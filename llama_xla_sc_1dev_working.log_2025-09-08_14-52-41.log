WARNING:root:Defaulting to PJRT_DEVICE=CPU
2025-09-08 14:24:46.326 (   0.000s) [        6D2F5000]      dylib_platform.cc:47       1| DylibPlatform::SubclassInitialize
2025-09-08 14:24:46.328 (   0.002s) [        6D2F5000]     client_instance.cc:38       1| ClientInstance::ClientInstance
2025-09-08 14:24:46.328 (   0.002s) [        6D2F5000]              client.cc:18       1| TTClientInstance::TTClientInstance
2025-09-08 14:24:46.328 (   0.002s) [        6D2F5000]     client_instance.cc:59       1| ClientInstance::Initialize
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]              stubs.inc:112   WARN| STUB: PJRT_Client_TopologyDescription
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     client_instance.cc:340      1| ClientInstance::PJRT_Client_PlatformVersion
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     client_instance.cc:320      1| ClientInstance::PJRT_Client_PlatformName
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     client_instance.cc:352      1| ClientInstance::PJRT_Client_Devices
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     client_instance.cc:365      1| ClientInstance::PJRT_Client_AddressableDevices
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     client_instance.cc:415      1| ClientInstance::PJRT_Client_AddressableMemories
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-08 14:24:50.242 (   3.915s) [        6D2F5000]        api_bindings.cc:76       1| PJRT_Plugin_Attributes
2025-09-08 14:24:50.242768: W torch_xla/csrc/runtime/profiler.cc:88] Profiler API not found for PJRT plugin
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:24:50.242 (   3.916s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 53.70it/s]
2025-09-08 14:24:51.652 (   5.325s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.652 (   5.326s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.652 (   5.326s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.653 (   5.326s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.653 (   5.326s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.653 (   5.326s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.653 (   5.326s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.653 (   5.326s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.653 (   5.327s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.653 (   5.327s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.653 (   5.327s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.653 (   5.327s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-08 14:24:51.654 (   5.327s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.654 (   5.328s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.702 (   5.375s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.702 (   5.375s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.702 (   5.375s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.702 (   5.375s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.702 (   5.375s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.704 (   5.377s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.704 (   5.377s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.704 (   5.377s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.704 (   5.377s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.704 (   5.377s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.704 (   5.378s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.704 (   5.378s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.704 (   5.378s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.704 (   5.378s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.704 (   5.378s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.705 (   5.378s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.705 (   5.378s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.705 (   5.378s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.705 (   5.378s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.705 (   5.378s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.706 (   5.379s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.706 (   5.379s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.706 (   5.379s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.706 (   5.380s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.706 (   5.380s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.709 (   5.382s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.709 (   5.382s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.709 (   5.382s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.709 (   5.383s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.709 (   5.383s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.712 (   5.385s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.712 (   5.385s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.712 (   5.385s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.712 (   5.386s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.712 (   5.386s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.715 (   5.388s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.715 (   5.388s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.715 (   5.388s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.715 (   5.389s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.715 (   5.389s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.715 (   5.389s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.716 (   5.389s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.717 (   5.390s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.717 (   5.390s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.717 (   5.390s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.717 (   5.391s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.717 (   5.391s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.718 (   5.391s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.718 (   5.392s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.718 (   5.392s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.719 (   5.393s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.719 (   5.393s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.719 (   5.393s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.720 (   5.393s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.720 (   5.393s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.722 (   5.396s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.722 (   5.396s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.722 (   5.396s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.723 (   5.396s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.723 (   5.396s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.725 (   5.399s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.725 (   5.399s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.725 (   5.399s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.726 (   5.399s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.726 (   5.399s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.728 (   5.402s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.728 (   5.402s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.728 (   5.402s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.728 (   5.402s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.729 (   5.402s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.729 (   5.403s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.729 (   5.403s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.729 (   5.403s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.729 (   5.403s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.730 (   5.403s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.731 (   5.404s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.731 (   5.404s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.731 (   5.404s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.731 (   5.404s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.731 (   5.404s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.732 (   5.405s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.732 (   5.405s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.732 (   5.405s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.732 (   5.406s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.732 (   5.406s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.733 (   5.406s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.733 (   5.406s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.733 (   5.406s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.733 (   5.406s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.733 (   5.406s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.735 (   5.408s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.735 (   5.408s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.735 (   5.408s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.735 (   5.408s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.735 (   5.408s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.738 (   5.411s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.738 (   5.411s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.738 (   5.411s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.738 (   5.411s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.738 (   5.411s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.741 (   5.414s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.741 (   5.414s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.741 (   5.414s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.741 (   5.414s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.741 (   5.414s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.744 (   5.417s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.745 (   5.418s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.745 (   5.418s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.745 (   5.418s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.745 (   5.419s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.745 (   5.419s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.746 (   5.419s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.746 (   5.419s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.746 (   5.419s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.746 (   5.419s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.746 (   5.419s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.746 (   5.420s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.746 (   5.420s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.746 (   5.420s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.746 (   5.420s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.746 (   5.420s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.748 (   5.421s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.748 (   5.421s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.748 (   5.421s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.748 (   5.421s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.748 (   5.421s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.751 (   5.424s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.751 (   5.424s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.751 (   5.424s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.751 (   5.424s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.751 (   5.424s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.753 (   5.427s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.753 (   5.427s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.753 (   5.427s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.754 (   5.427s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.754 (   5.427s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.756 (   5.430s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.756 (   5.430s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.756 (   5.430s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.756 (   5.430s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.756 (   5.430s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.757 (   5.430s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.758 (   5.431s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.758 (   5.431s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.758 (   5.431s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.758 (   5.431s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.758 (   5.431s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.759 (   5.432s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.759 (   5.432s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.759 (   5.432s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.759 (   5.432s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.759 (   5.432s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.760 (   5.433s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.760 (   5.433s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.760 (   5.433s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.760 (   5.433s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.760 (   5.433s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.761 (   5.434s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.761 (   5.434s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.761 (   5.434s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.761 (   5.434s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.761 (   5.434s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.764 (   5.437s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.764 (   5.437s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.764 (   5.437s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.764 (   5.437s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.764 (   5.437s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.767 (   5.440s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.767 (   5.440s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.767 (   5.440s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.767 (   5.440s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.767 (   5.440s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.770 (   5.443s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.771 (   5.445s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.771 (   5.445s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.771 (   5.445s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.771 (   5.445s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.771 (   5.445s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.772 (   5.445s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.772 (   5.445s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.772 (   5.445s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.772 (   5.445s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.772 (   5.445s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.772 (   5.446s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.772 (   5.446s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.772 (   5.446s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.772 (   5.446s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.772 (   5.446s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.774 (   5.447s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.774 (   5.447s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.774 (   5.447s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.774 (   5.447s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.774 (   5.447s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.777 (   5.450s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.777 (   5.450s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.777 (   5.450s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.777 (   5.450s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.777 (   5.450s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.780 (   5.453s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.780 (   5.453s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.780 (   5.453s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.780 (   5.453s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.780 (   5.453s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.783 (   5.456s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.783 (   5.457s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.785 (   5.458s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.785 (   5.459s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.785 (   5.459s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.785 (   5.459s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.786 (   5.459s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.786 (   5.459s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.786 (   5.459s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.786 (   5.459s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.786 (   5.459s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.787 (   5.460s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.787 (   5.460s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.787 (   5.460s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.787 (   5.460s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.787 (   5.460s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.790 (   5.463s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.790 (   5.463s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.790 (   5.463s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.790 (   5.464s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.790 (   5.464s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.793 (   5.467s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.793 (   5.467s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.793 (   5.467s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.793 (   5.467s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.793 (   5.467s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.796 (   5.470s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.796 (   5.470s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.796 (   5.470s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.796 (   5.470s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.796 (   5.470s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.797 (   5.470s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.798 (   5.471s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.798 (   5.471s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.798 (   5.471s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.798 (   5.471s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.798 (   5.471s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.799 (   5.472s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.799 (   5.472s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.799 (   5.472s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.799 (   5.472s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.799 (   5.472s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.799 (   5.473s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.799 (   5.473s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.799 (   5.473s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.799 (   5.473s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.799 (   5.473s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.801 (   5.474s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.801 (   5.474s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.801 (   5.474s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.801 (   5.474s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.801 (   5.474s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.804 (   5.477s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.804 (   5.477s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.804 (   5.477s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.804 (   5.477s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.804 (   5.477s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.807 (   5.480s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.807 (   5.480s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.807 (   5.480s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.807 (   5.480s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.807 (   5.480s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.810 (   5.483s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.810 (   5.484s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.810 (   5.484s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.810 (   5.484s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.810 (   5.484s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.810 (   5.484s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.812 (   5.485s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.812 (   5.486s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.813 (   5.486s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.813 (   5.486s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.813 (   5.486s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.813 (   5.486s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.813 (   5.486s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.814 (   5.487s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.814 (   5.487s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.814 (   5.487s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.814 (   5.487s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.814 (   5.487s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.817 (   5.490s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.817 (   5.490s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.817 (   5.490s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.817 (   5.491s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.817 (   5.491s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.820 (   5.494s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.820 (   5.494s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.820 (   5.494s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.820 (   5.494s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.820 (   5.494s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.823 (   5.497s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.823 (   5.497s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.823 (   5.497s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.824 (   5.497s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.825 (   5.498s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.825 (   5.498s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.825 (   5.498s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.825 (   5.498s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.825 (   5.498s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.826 (   5.499s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.826 (   5.499s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.826 (   5.499s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.826 (   5.499s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.826 (   5.499s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.826 (   5.500s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.826 (   5.500s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.826 (   5.500s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.826 (   5.500s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.826 (   5.500s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.828 (   5.501s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.828 (   5.501s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.828 (   5.501s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.828 (   5.501s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.828 (   5.501s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.831 (   5.504s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.831 (   5.504s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.831 (   5.504s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.831 (   5.504s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.831 (   5.504s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.834 (   5.507s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.834 (   5.507s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.834 (   5.507s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.834 (   5.507s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.834 (   5.507s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.837 (   5.510s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.837 (   5.511s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.839 (   5.512s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.839 (   5.512s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.839 (   5.512s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.839 (   5.512s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.839 (   5.512s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.839 (   5.513s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.839 (   5.513s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.839 (   5.513s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.839 (   5.513s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.839 (   5.513s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.840 (   5.513s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.840 (   5.513s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.840 (   5.513s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.840 (   5.513s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.840 (   5.513s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.841 (   5.515s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.841 (   5.515s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.841 (   5.515s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.841 (   5.515s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.841 (   5.515s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.845 (   5.518s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.845 (   5.518s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.845 (   5.518s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.845 (   5.518s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.845 (   5.518s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.848 (   5.521s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.848 (   5.521s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.848 (   5.521s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.848 (   5.521s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.848 (   5.521s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.851 (   5.524s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.851 (   5.524s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.851 (   5.524s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.851 (   5.525s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.852 (   5.525s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.852 (   5.525s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.853 (   5.526s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.853 (   5.526s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.853 (   5.526s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.853 (   5.526s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.853 (   5.526s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.853 (   5.527s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.853 (   5.527s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.853 (   5.527s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.854 (   5.527s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.855 (   5.529s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.855 (   5.529s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.855 (   5.529s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.856 (   5.529s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.856 (   5.529s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.859 (   5.532s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.859 (   5.532s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.859 (   5.532s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.859 (   5.532s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.859 (   5.532s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.862 (   5.535s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.862 (   5.535s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.862 (   5.535s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.862 (   5.536s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.862 (   5.536s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.865 (   5.539s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.865 (   5.539s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.865 (   5.539s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.866 (   5.539s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.867 (   5.541s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.867 (   5.541s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.867 (   5.541s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.867 (   5.541s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.867 (   5.541s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.868 (   5.541s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.868 (   5.541s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.868 (   5.541s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.868 (   5.541s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.868 (   5.541s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.868 (   5.542s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.868 (   5.542s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.868 (   5.542s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.869 (   5.542s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.869 (   5.542s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.870 (   5.543s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.870 (   5.543s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.870 (   5.543s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.870 (   5.543s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.870 (   5.543s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.873 (   5.546s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.873 (   5.546s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.873 (   5.546s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.873 (   5.547s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.873 (   5.547s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.876 (   5.550s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.876 (   5.550s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.876 (   5.550s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.877 (   5.550s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.877 (   5.550s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.880 (   5.553s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.880 (   5.554s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.881 (   5.555s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.882 (   5.555s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.882 (   5.556s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.882 (   5.556s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.883 (   5.556s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.883 (   5.556s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.883 (   5.556s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.883 (   5.556s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.883 (   5.556s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.884 (   5.557s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.884 (   5.557s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.884 (   5.557s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.884 (   5.558s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.884 (   5.558s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.887 (   5.561s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.887 (   5.561s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.887 (   5.561s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.888 (   5.561s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.888 (   5.561s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.891 (   5.564s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.891 (   5.564s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.891 (   5.564s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.891 (   5.564s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.891 (   5.564s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.894 (   5.567s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.894 (   5.567s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.894 (   5.567s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.894 (   5.567s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.894 (   5.567s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.894 (   5.568s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.895 (   5.568s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.895 (   5.568s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.896 (   5.569s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.896 (   5.569s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.896 (   5.569s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.896 (   5.569s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.896 (   5.569s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.896 (   5.570s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.896 (   5.570s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.896 (   5.570s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.897 (   5.570s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.898 (   5.572s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.898 (   5.572s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.898 (   5.572s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.899 (   5.572s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.899 (   5.572s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.902 (   5.575s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.902 (   5.575s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.902 (   5.575s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.902 (   5.575s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.902 (   5.575s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.906 (   5.579s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.906 (   5.579s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.906 (   5.579s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.906 (   5.579s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.906 (   5.579s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.909 (   5.583s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.910 (   5.583s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.911 (   5.584s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.911 (   5.584s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.911 (   5.584s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.911 (   5.585s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.911 (   5.585s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.912 (   5.585s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.912 (   5.585s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.912 (   5.585s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.912 (   5.585s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.912 (   5.585s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.913 (   5.586s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.913 (   5.586s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.913 (   5.586s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.913 (   5.586s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.913 (   5.586s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.914 (   5.587s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.914 (   5.587s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.914 (   5.587s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.914 (   5.587s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.914 (   5.587s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.918 (   5.591s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.918 (   5.591s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.918 (   5.591s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.918 (   5.591s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.918 (   5.591s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.921 (   5.595s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.922 (   5.595s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.922 (   5.595s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.922 (   5.595s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.922 (   5.595s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.925 (   5.599s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.926 (   5.599s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.926 (   5.599s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.926 (   5.599s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.926 (   5.599s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.926 (   5.599s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.927 (   5.600s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.927 (   5.600s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.927 (   5.600s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.927 (   5.600s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.927 (   5.600s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.928 (   5.601s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.928 (   5.601s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.928 (   5.601s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.928 (   5.601s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.928 (   5.601s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.928 (   5.602s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.928 (   5.602s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.928 (   5.602s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.929 (   5.602s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.929 (   5.602s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.930 (   5.603s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.930 (   5.603s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.930 (   5.603s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.930 (   5.603s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.930 (   5.603s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.934 (   5.607s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.934 (   5.607s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.934 (   5.607s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.934 (   5.607s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.934 (   5.607s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.937 (   5.611s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.937 (   5.611s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.937 (   5.611s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.937 (   5.611s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.937 (   5.611s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.941 (   5.614s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.941 (   5.614s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.941 (   5.614s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.941 (   5.614s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.941 (   5.615s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.942 (   5.615s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.942 (   5.615s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.943 (   5.616s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.943 (   5.616s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.943 (   5.616s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.943 (   5.616s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.943 (   5.616s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.944 (   5.617s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.944 (   5.617s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.944 (   5.617s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.944 (   5.617s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.944 (   5.617s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.944 (   5.618s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.944 (   5.618s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.944 (   5.618s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.944 (   5.618s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.944 (   5.618s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.946 (   5.619s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.946 (   5.619s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.946 (   5.619s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.946 (   5.619s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.946 (   5.619s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.950 (   5.623s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.950 (   5.623s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.950 (   5.623s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.950 (   5.623s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.950 (   5.623s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.953 (   5.627s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.953 (   5.627s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.953 (   5.627s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.953 (   5.627s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.953 (   5.627s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.957 (   5.630s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.957 (   5.631s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.959 (   5.632s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.959 (   5.632s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.959 (   5.632s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.959 (   5.632s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.959 (   5.632s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.960 (   5.633s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.960 (   5.634s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.960 (   5.634s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.962 (   5.635s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.962 (   5.635s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.962 (   5.635s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.962 (   5.635s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.962 (   5.635s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.965 (   5.639s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.965 (   5.639s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.965 (   5.639s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.966 (   5.639s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.966 (   5.639s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.969 (   5.643s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.969 (   5.643s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.969 (   5.643s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.969 (   5.643s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.969 (   5.643s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.973 (   5.646s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.973 (   5.647s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.975 (   5.648s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.975 (   5.648s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.975 (   5.648s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.975 (   5.648s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.975 (   5.648s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.975 (   5.649s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.975 (   5.649s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.975 (   5.649s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.976 (   5.649s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.976 (   5.649s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.976 (   5.649s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.976 (   5.649s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.976 (   5.649s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.976 (   5.650s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.976 (   5.650s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.978 (   5.651s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.978 (   5.651s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.978 (   5.651s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.978 (   5.651s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.978 (   5.651s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.981 (   5.655s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.981 (   5.655s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.981 (   5.655s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.981 (   5.655s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.981 (   5.655s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.985 (   5.658s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.985 (   5.658s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.985 (   5.658s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.985 (   5.658s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.985 (   5.658s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.989 (   5.662s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.989 (   5.663s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.991 (   5.664s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.991 (   5.664s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.991 (   5.664s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.991 (   5.664s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.991 (   5.664s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.992 (   5.665s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.992 (   5.666s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.992 (   5.666s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.994 (   5.667s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.994 (   5.667s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.994 (   5.667s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.994 (   5.667s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.994 (   5.667s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:51.997 (   5.671s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:51.997 (   5.671s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:51.997 (   5.671s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:51.998 (   5.671s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:51.998 (   5.671s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.001 (   5.674s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.001 (   5.675s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.001 (   5.675s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.001 (   5.675s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.001 (   5.675s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.005 (   5.678s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.005 (   5.679s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.007 (   5.680s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.007 (   5.680s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.007 (   5.680s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.007 (   5.680s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.007 (   5.680s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.008 (   5.681s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.008 (   5.682s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.008 (   5.682s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.008 (   5.682s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.008 (   5.682s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.010 (   5.683s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.010 (   5.683s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.010 (   5.683s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.010 (   5.683s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.010 (   5.683s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.013 (   5.687s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.013 (   5.687s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.013 (   5.687s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.014 (   5.687s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.014 (   5.687s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.017 (   5.691s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.017 (   5.691s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.017 (   5.691s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.017 (   5.691s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.017 (   5.691s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.021 (   5.694s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.021 (   5.695s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.023 (   5.696s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.023 (   5.696s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.023 (   5.696s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.023 (   5.696s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.023 (   5.696s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.023 (   5.697s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.023 (   5.697s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.023 (   5.697s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.024 (   5.697s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.024 (   5.698s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.026 (   5.699s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.026 (   5.699s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.026 (   5.699s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.026 (   5.699s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.026 (   5.699s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.029 (   5.703s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.029 (   5.703s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.029 (   5.703s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.030 (   5.703s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.030 (   5.703s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.033 (   5.707s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.033 (   5.707s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.033 (   5.707s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.033 (   5.707s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.033 (   5.707s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.037 (   5.710s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.037 (   5.710s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.037 (   5.710s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.037 (   5.710s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.037 (   5.710s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.037 (   5.711s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.039 (   5.712s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.039 (   5.712s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.039 (   5.712s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.039 (   5.712s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.039 (   5.712s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.040 (   5.713s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.040 (   5.713s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.040 (   5.713s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.040 (   5.713s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.040 (   5.713s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.040 (   5.714s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.040 (   5.714s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.040 (   5.714s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.040 (   5.714s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.040 (   5.714s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.042 (   5.715s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.042 (   5.715s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.042 (   5.715s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.042 (   5.715s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.042 (   5.715s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.046 (   5.719s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.046 (   5.719s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.046 (   5.719s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.046 (   5.719s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.046 (   5.719s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.049 (   5.723s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.049 (   5.723s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.049 (   5.723s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.050 (   5.723s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.050 (   5.723s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.053 (   5.727s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.054 (   5.727s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.055 (   5.728s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.055 (   5.728s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.055 (   5.728s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.055 (   5.729s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.055 (   5.729s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.056 (   5.729s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.056 (   5.729s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.056 (   5.729s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.056 (   5.729s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.056 (   5.729s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.056 (   5.730s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.056 (   5.730s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.056 (   5.730s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.057 (   5.730s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.057 (   5.730s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.058 (   5.731s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.058 (   5.731s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.058 (   5.731s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.058 (   5.731s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.058 (   5.731s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.062 (   5.735s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.062 (   5.735s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.062 (   5.735s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.062 (   5.735s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.062 (   5.735s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.066 (   5.739s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.066 (   5.739s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.066 (   5.739s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.066 (   5.739s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.066 (   5.739s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.069 (   5.743s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.069 (   5.743s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.069 (   5.743s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.070 (   5.743s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.071 (   5.745s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.071 (   5.745s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.071 (   5.745s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.071 (   5.745s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.071 (   5.745s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.072 (   5.745s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.072 (   5.745s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.072 (   5.745s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.072 (   5.745s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.072 (   5.745s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.073 (   5.746s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.073 (   5.746s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.073 (   5.746s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.073 (   5.746s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.073 (   5.746s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.074 (   5.748s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.074 (   5.748s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.074 (   5.748s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.074 (   5.748s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.074 (   5.748s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.078 (   5.751s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.078 (   5.751s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.078 (   5.751s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.078 (   5.751s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.078 (   5.751s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.082 (   5.755s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.082 (   5.755s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.082 (   5.755s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.082 (   5.755s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.082 (   5.755s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.086 (   5.759s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.088 (   5.761s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.088 (   5.761s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.088 (   5.761s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.088 (   5.761s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.088 (   5.761s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.088 (   5.762s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.088 (   5.762s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.088 (   5.762s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.088 (   5.762s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.088 (   5.762s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.089 (   5.762s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.089 (   5.762s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.089 (   5.762s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.089 (   5.762s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.089 (   5.762s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.090 (   5.764s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.090 (   5.764s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.091 (   5.764s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.091 (   5.764s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.091 (   5.764s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.094 (   5.768s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.094 (   5.768s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.094 (   5.768s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.094 (   5.768s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.094 (   5.768s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.098 (   5.771s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.098 (   5.771s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.098 (   5.771s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.098 (   5.771s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.098 (   5.772s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.102 (   5.775s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.102 (   5.776s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.102 (   5.776s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.102 (   5.776s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.102 (   5.776s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.102 (   5.776s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.104 (   5.777s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.104 (   5.777s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.104 (   5.777s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.104 (   5.777s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.104 (   5.777s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.104 (   5.778s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.104 (   5.778s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.104 (   5.778s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.105 (   5.778s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.105 (   5.778s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.105 (   5.778s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.105 (   5.778s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.105 (   5.778s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.105 (   5.779s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.105 (   5.779s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.107 (   5.780s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.107 (   5.780s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.107 (   5.780s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.107 (   5.780s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.107 (   5.780s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.110 (   5.784s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.110 (   5.784s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.110 (   5.784s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.111 (   5.784s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.111 (   5.784s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.114 (   5.788s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.114 (   5.788s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.114 (   5.788s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.114 (   5.788s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.114 (   5.788s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.118 (   5.791s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.118 (   5.791s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.118 (   5.791s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.118 (   5.792s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.119 (   5.792s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.148 (   5.822s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.149 (   5.822s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.149 (   5.822s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.149 (   5.822s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.149 (   5.822s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:52.203 (   5.876s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:52.203 (   5.876s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:52.203 (   5.876s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:52.203 (   5.877s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:52.203 (   5.877s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.500 (   7.174s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:24:53.500 (   7.174s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:24:53.500 (   7.174s) [        6D2F5000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:24:53.501 (   7.174s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:24:53.501 (   7.174s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User is requesting to copy the data from a runtime tensor with data type: Int32 into buffer with expected data type: Int64, the values will be casted, this may impact the throughput and the integrity of the data.
2025-09-08 14:24:53.501 (   7.174s) [        BBFFF640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.510 (   7.183s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:24:53.510 (   7.183s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:24:53.510 (   7.183s) [        6D2F5000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:24:53.510 (   7.183s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:24:53.510 (   7.184s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User is requesting to copy the data from a runtime tensor with data type: Int32 into buffer with expected data type: Int64, the values will be casted, this may impact the throughput and the integrity of the data.
2025-09-08 14:24:53.510 (   7.184s) [        3DFFB640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.511 (   7.184s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:24:53.511 (   7.184s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:24:53.511 (   7.184s) [        6D2F5000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:24:53.511 (   7.184s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:24:53.511 (   7.184s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.511 (   7.184s) [        3DFFB640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.514 (   7.188s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:24:53.514 (   7.188s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:24:53.514 (   7.188s) [        6D2F5000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:24:53.514 (   7.188s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:24:53.514 (   7.188s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.515 (   7.188s) [        3DFFB640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.519 (   7.192s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:53.519 (   7.192s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:53.519 (   7.192s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:53.519 (   7.192s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.519 (   7.193s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.522 (   7.196s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:53.523 (   7.196s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:53.523 (   7.196s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:53.523 (   7.196s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.523 (   7.196s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.524 (   7.197s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:53.524 (   7.197s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:53.524 (   7.197s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-08 14:24:53.524 (   7.198s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.524 (   7.198s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.525 (   7.198s) [        6D2F5000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-08 14:24:53.525 (   7.198s) [        6D2F5000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-08 14:24:53.525 (   7.198s) [        6D2F5000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-08 14:24:53.525 (   7.198s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:24:53.525 (   7.198s) [        6D2F5000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.201s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.528 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.202s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.203s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.203s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.529 (   7.203s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:24:53.551 (   7.225s) [        6D2F5000]     client_instance.cc:428      1| ClientInstance::PJRT_Client_Compile
2025-09-08 14:24:53.552 (   7.225s) [        6D2F5000]      module_builder.cc:98       1| ModuleBuilder::buildModule
2025-09-08 14:24:53.554 (   7.227s) [        6D2F5000]      module_builder.cc:160      1| VHLO Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg7: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg10: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg14: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg15: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<7x1024xbf16>>}> : () -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<7x1024xi64>>}> : () -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<1x7x3072xf32>>}> : () -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<1024xi64>>}> : () -> !vhlo.tensor_v1<1024x!vhlo.i64_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %9 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %10 = "vhlo.custom_call_v1"(%9) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %11 = "vhlo.reshape_v1"(%10) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %12 = "vhlo.convert_v1"(%11) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %13 = "vhlo.broadcast_in_dim_v1"(%12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %14 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %15 = "vhlo.custom_call_v1"(%14) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %17 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %20 = "vhlo.convert_v1"(%19) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %21 = "vhlo.gather_v2"(%16, %20) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %23 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %24 = "vhlo.custom_call_v1"(%23) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %26 = "vhlo.convert_v1"(%25) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %27 = "vhlo.broadcast_in_dim_v1"(%26) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%22) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %29 = "vhlo.power_v1"(%28, %4) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %30 = "vhlo.reduce_v1"(%29, %8) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %239 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%239) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %31 = "vhlo.multiply_v1"(%30, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %33 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %34 = "vhlo.add_v1"(%32, %33) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %35 = "vhlo.rsqrt_v1"(%34) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %36 = "vhlo.reshape_v1"(%35) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %37 = "vhlo.broadcast_in_dim_v1"(%36) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %38 = "vhlo.multiply_v1"(%28, %37) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %39 = "vhlo.convert_v1"(%38) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %41 = "vhlo.multiply_v1"(%27, %40) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %42 = "vhlo.convert_v1"(%41) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %43 = "vhlo.reshape_v1"(%42) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %44 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %45 = "vhlo.custom_call_v1"(%44) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %47 = "vhlo.transpose_v1"(%46) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %48 = "vhlo.dot_general_v2"(%43, %47) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %49 = "vhlo.reshape_v1"(%48) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %50 = "vhlo.transpose_v1"(%49) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %51 = "vhlo.convert_v1"(%50) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %52 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %53 = "vhlo.custom_call_v1"(%52) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %54 = "vhlo.reshape_v1"(%53) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %55 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %56 = "vhlo.custom_call_v1"(%55) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %57 = "vhlo.reshape_v1"(%56) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %58 = "vhlo.convert_v1"(%56) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %59 = "vhlo.dot_general_v2"(%54, %58) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %60 = "vhlo.transpose_v1"(%59) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %61 = "vhlo.concatenate_v1"(%60, %60) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %62 = "vhlo.cosine_v1"(%61) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %64 = "vhlo.reshape_v1"(%63) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %65 = "vhlo.convert_v1"(%64) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %66 = "vhlo.reshape_v1"(%65) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %67 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %68 = "vhlo.multiply_v1"(%51, %67) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %69 = "vhlo.convert_v1"(%68) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %70 = "vhlo.slice_v1"(%50) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %71 = "vhlo.negate_v1"(%70) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %72 = "vhlo.slice_v1"(%50) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %73 = "vhlo.concatenate_v1"(%71, %72) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %74 = "vhlo.convert_v1"(%73) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %75 = "vhlo.sine_v1"(%61) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %76 = "vhlo.convert_v1"(%75) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %77 = "vhlo.reshape_v1"(%76) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %78 = "vhlo.convert_v1"(%77) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %79 = "vhlo.reshape_v1"(%78) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %80 = "vhlo.broadcast_in_dim_v1"(%79) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %81 = "vhlo.multiply_v1"(%74, %80) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %82 = "vhlo.convert_v1"(%81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %83 = "vhlo.add_v1"(%69, %82) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %84 = "vhlo.reshape_v1"(%83) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %85 = "vhlo.custom_call_v1"(%arg16) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %86 = "vhlo.compare_v1"(%57, %2) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %87 = "vhlo.broadcast_in_dim_v1"(%arg10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %88 = "vhlo.add_v1"(%57, %87) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %89 = "vhlo.select_v1"(%86, %88, %57) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %91 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %92 = "vhlo.custom_call_v1"(%91) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %94 = "vhlo.transpose_v1"(%93) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %95 = "vhlo.dot_general_v2"(%43, %94) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %98 = "vhlo.convert_v1"(%97) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %99 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %100 = "vhlo.multiply_v1"(%98, %99) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %101 = "vhlo.convert_v1"(%100) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %102 = "vhlo.slice_v1"(%97) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %103 = "vhlo.negate_v1"(%102) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %104 = "vhlo.slice_v1"(%97) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %105 = "vhlo.concatenate_v1"(%103, %104) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %106 = "vhlo.convert_v1"(%105) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %107 = "vhlo.broadcast_in_dim_v1"(%79) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %108 = "vhlo.multiply_v1"(%106, %107) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %109 = "vhlo.convert_v1"(%108) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %110 = "vhlo.add_v1"(%101, %109) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %111 = "vhlo.scatter_v2"(%85, %90, %110) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %112 = "vhlo.broadcast_in_dim_v1"(%111) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %113 = "vhlo.reshape_v1"(%112) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>
    %114 = "vhlo.transpose_v1"(%113) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,1024]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>
    %115 = "vhlo.reshape_v1"(%114) : (!vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>
    %116 = "vhlo.dot_general_v2"(%84, %115) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %117 = "vhlo.reshape_v1"(%116) : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %118 = "vhlo.convert_v1"(%117) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %119 = "vhlo.broadcast_in_dim_v1"(%arg13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %120 = "vhlo.multiply_v1"(%118, %119) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %122 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %123 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %124 = "vhlo.subtract_v1"(%122, %123) : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %125 = "vhlo.compare_v1"(%124, %1) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %126 = "vhlo.broadcast_in_dim_v1"(%arg12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %127 = "vhlo.select_v1"(%125, %126, %0) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %128 = "vhlo.convert_v1"(%127) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%57) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %130 = "vhlo.compare_v1"(%122, %129) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %132 = "vhlo.multiply_v1"(%128, %131) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %133 = "vhlo.convert_v1"(%132) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %134 = "vhlo.reshape_v1"(%133) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>
    %135 = "vhlo.broadcast_in_dim_v1"(%134) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %136 = "vhlo.add_v1"(%121, %135) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %137 = "vhlo.convert_v1"(%136) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %138 = "vhlo.reduce_v1"(%137, %5) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %239 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%239) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %139 = "vhlo.broadcast_in_dim_v1"(%138) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %140 = "vhlo.subtract_v1"(%137, %139) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %141 = "vhlo.exponential_v2"(%140) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %142 = "vhlo.reduce_v1"(%141, %8) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %239 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%239) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %143 = "vhlo.broadcast_in_dim_v1"(%142) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %144 = "vhlo.divide_v1"(%141, %143) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %145 = "vhlo.convert_v1"(%144) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %146 = "vhlo.reshape_v1"(%145) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %147 = "vhlo.custom_call_v1"(%arg11) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %148 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %149 = "vhlo.custom_call_v1"(%148) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %150 = "vhlo.reshape_v1"(%149) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %151 = "vhlo.transpose_v1"(%150) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %152 = "vhlo.dot_general_v2"(%43, %151) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %154 = "vhlo.transpose_v1"(%153) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %155 = "vhlo.scatter_v2"(%147, %90, %154) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %156 = "vhlo.broadcast_in_dim_v1"(%155) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %157 = "vhlo.reshape_v1"(%156) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>
    %158 = "vhlo.dot_general_v2"(%146, %157) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %159 = "vhlo.reshape_v1"(%158) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %160 = "vhlo.transpose_v1"(%159) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %163 = "vhlo.custom_call_v1"(%162) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %165 = "vhlo.transpose_v1"(%164) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %166 = "vhlo.dot_general_v2"(%161, %165) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %168 = "vhlo.add_v1"(%22, %167) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %169 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %170 = "vhlo.custom_call_v1"(%169) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %171 = "vhlo.reshape_v1"(%170) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %172 = "vhlo.convert_v1"(%171) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %173 = "vhlo.broadcast_in_dim_v1"(%172) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %174 = "vhlo.convert_v1"(%168) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %175 = "vhlo.power_v1"(%174, %4) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %176 = "vhlo.reduce_v1"(%175, %8) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %239 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%239) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %177 = "vhlo.multiply_v1"(%176, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %178 = "vhlo.reshape_v1"(%177) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %179 = "vhlo.add_v1"(%178, %33) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %180 = "vhlo.rsqrt_v1"(%179) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %182 = "vhlo.broadcast_in_dim_v1"(%181) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %183 = "vhlo.multiply_v1"(%174, %182) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %184 = "vhlo.convert_v1"(%183) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %185 = "vhlo.convert_v1"(%184) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %186 = "vhlo.multiply_v1"(%173, %185) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %187 = "vhlo.convert_v1"(%186) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %189 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %190 = "vhlo.custom_call_v1"(%189) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %192 = "vhlo.transpose_v1"(%191) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %193 = "vhlo.dot_general_v2"(%188, %192) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %195 = "vhlo.convert_v1"(%194) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %196 = "vhlo.logistic_v1"(%194) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %197 = "vhlo.convert_v1"(%196) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %198 = "vhlo.multiply_v1"(%195, %197) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %199 = "vhlo.convert_v1"(%198) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %201 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %202 = "vhlo.custom_call_v1"(%201) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %203 = "vhlo.reshape_v1"(%202) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %204 = "vhlo.transpose_v1"(%203) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %205 = "vhlo.dot_general_v2"(%188, %204) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %207 = "vhlo.convert_v1"(%206) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %208 = "vhlo.multiply_v1"(%200, %207) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %209 = "vhlo.convert_v1"(%208) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %210 = "vhlo.reshape_v1"(%209) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %211 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %212 = "vhlo.custom_call_v1"(%211) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %214 = "vhlo.transpose_v1"(%213) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %215 = "vhlo.dot_general_v2"(%210, %214) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %217 = "vhlo.add_v1"(%168, %216) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %218 = "vhlo.convert_v1"(%217) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %219 = "vhlo.power_v1"(%218, %4) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %220 = "vhlo.reduce_v1"(%219, %8) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %239 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%239) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %221 = "vhlo.multiply_v1"(%220, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %223 = "vhlo.add_v1"(%222, %33) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %224 = "vhlo.rsqrt_v1"(%223) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %225 = "vhlo.reshape_v1"(%224) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %226 = "vhlo.broadcast_in_dim_v1"(%225) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %227 = "vhlo.multiply_v1"(%218, %226) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %228 = "vhlo.convert_v1"(%227) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %229 = "vhlo.convert_v1"(%228) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %230 = "vhlo.multiply_v1"(%13, %229) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %231 = "vhlo.convert_v1"(%230) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %232 = "vhlo.reshape_v1"(%231) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %233 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %234 = "vhlo.custom_call_v1"(%233) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %235 = "vhlo.reshape_v1"(%234) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %236 = "vhlo.transpose_v1"(%235) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %237 = "vhlo.dot_general_v2"(%232, %236) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%238) : (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
2025-09-08 14:24:53.568 (   7.242s) [        6D2F5000]      module_builder.cc:178      1| SHLO Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<128256x3072xbf16>, %arg1: tensor<f32>, %arg2: tensor<3072x8192xbf16>, %arg3: tensor<8192x3072xbf16>, %arg4: tensor<3072x3072xbf16>, %arg5: tensor<1024x3072xbf16>, %arg6: tensor<1x7xi64>, %arg7: tensor<128256x3072xbf16>, %arg8: tensor<3072xbf16>, %arg9: tensor<7xi64>, %arg10: tensor<i64>, %arg11: tensor<1x8x1024x128xbf16>, %arg12: tensor<bf16>, %arg13: tensor<f32>, %arg14: tensor<64xf32>, %arg15: tensor<1024x3072xbf16>, %arg16: tensor<1x8x1024x128xbf16>, %arg17: tensor<3072x3072xbf16>, %arg18: tensor<3072xbf16>, %arg19: tensor<8192x3072xbf16>, %arg20: tensor<3072xbf16>) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<7x1024xbf16>
    %c = stablehlo.constant dense<1> : tensor<7x1024xi64>
    %c_0 = stablehlo.constant dense<0> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<1x7x3072xf32>
    %cst_3 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %c_4 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<"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tensor<1024xi64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %1 = stablehlo.custom_call @tt.mark_argument(%0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %2 = stablehlo.reshape %1 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %3 = stablehlo.convert %2 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %4 = stablehlo.broadcast_in_dim %3, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %5 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %6 = stablehlo.custom_call @tt.mark_argument(%5) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %7 = stablehlo.reshape %6 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %8 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %9 = stablehlo.custom_call @tt.mark_argument(%8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.reshape %9 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %11 = stablehlo.convert %10 : (tensor<7xi64>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%7, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.custom_call @tt.mark_argument(%14) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %17 = stablehlo.convert %16 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %18 = stablehlo.broadcast_in_dim %17, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %20 = stablehlo.power %19, %cst_2 : tensor<1x7x3072xf32>
    %21 = stablehlo.reduce(%20 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %22 = stablehlo.multiply %21, %cst_1 : tensor<1x7xf32>
    %23 = stablehlo.reshape %22 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %25 = stablehlo.add %23, %24 : tensor<1x7x1xf32>
    %26 = stablehlo.rsqrt %25 : tensor<1x7x1xf32>
    %27 = stablehlo.reshape %26 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %29 = stablehlo.multiply %19, %28 : tensor<1x7x3072xf32>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %31 = stablehlo.convert %30 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %32 = stablehlo.multiply %18, %31 : tensor<1x7x3072xf32>
    %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %34 = stablehlo.reshape %33 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %35 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %36 = stablehlo.custom_call @tt.mark_argument(%35) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %37 = stablehlo.reshape %36 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %38 = stablehlo.transpose %37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %39 = stablehlo.dot_general %34, %38, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %40 = stablehlo.reshape %39 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %42 = stablehlo.convert %41 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %43 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %44 = stablehlo.custom_call @tt.mark_argument(%43) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %46 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %47 = stablehlo.custom_call @tt.mark_argument(%46) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %48 = stablehlo.reshape %47 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %49 = stablehlo.convert %47 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %50 = stablehlo.dot_general %45, %49, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %51 = stablehlo.transpose %50, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %52 = stablehlo.concatenate %51, %51, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %53 = stablehlo.cosine %52 : tensor<1x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %55 = stablehlo.reshape %54 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %56 = stablehlo.convert %55 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %57 = stablehlo.reshape %56 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %58 = stablehlo.broadcast_in_dim %57, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %59 = stablehlo.multiply %42, %58 : tensor<1x24x7x128xf32>
    %60 = stablehlo.convert %59 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %61 = stablehlo.slice %41 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %62 = stablehlo.negate %61 : tensor<1x24x7x64xbf16>
    %63 = stablehlo.slice %41 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %64 = stablehlo.concatenate %62, %63, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %66 = stablehlo.sine %52 : tensor<1x7x128xf32>
    %67 = stablehlo.convert %66 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %69 = stablehlo.convert %68 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %70 = stablehlo.reshape %69 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %71 = stablehlo.broadcast_in_dim %70, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %72 = stablehlo.multiply %65, %71 : tensor<1x24x7x128xf32>
    %73 = stablehlo.convert %72 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %74 = stablehlo.add %60, %73 : tensor<1x24x7x128xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %76 = stablehlo.custom_call @tt.mark_argument(%arg16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %77 = stablehlo.compare  LT, %48, %c_0 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %78 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %79 = stablehlo.add %48, %78 : tensor<7xi64>
    %80 = stablehlo.select %77, %79, %48 : tensor<7xi1>, tensor<7xi64>
    %81 = stablehlo.reshape %80 : (tensor<7xi64>) -> tensor<7x1xi64>
    %82 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %83 = stablehlo.custom_call @tt.mark_argument(%82) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %84 = stablehlo.reshape %83 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %85 = stablehlo.transpose %84, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %86 = stablehlo.dot_general %34, %85, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %87 = stablehlo.reshape %86 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %89 = stablehlo.convert %88 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %90 = stablehlo.broadcast_in_dim %57, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %91 = stablehlo.multiply %89, %90 : tensor<1x8x7x128xf32>
    %92 = stablehlo.convert %91 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %93 = stablehlo.slice %88 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %94 = stablehlo.negate %93 : tensor<1x8x7x64xbf16>
    %95 = stablehlo.slice %88 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %96 = stablehlo.concatenate %94, %95, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %97 = stablehlo.convert %96 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %98 = stablehlo.broadcast_in_dim %70, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %99 = stablehlo.multiply %97, %98 : tensor<1x8x7x128xf32>
    %100 = stablehlo.convert %99 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %101 = stablehlo.add %92, %100 : tensor<1x8x7x128xbf16>
    %102 = "stablehlo.scatter"(%76, %81, %101) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %103 = stablehlo.broadcast_in_dim %102, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %104 = stablehlo.reshape %103 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %105 = stablehlo.transpose %104, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %106 = stablehlo.reshape %105 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %107 = stablehlo.dot_general %75, %106, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %108 = stablehlo.reshape %107 : (tensor<24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %111 = stablehlo.multiply %109, %110 : tensor<1x24x7x1024xf32>
    %112 = stablehlo.convert %111 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %113 = stablehlo.broadcast_in_dim %c_5, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %114 = stablehlo.broadcast_in_dim %c_4, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %115 = stablehlo.subtract %113, %114 : tensor<7x1024xi64>
    %116 = stablehlo.compare  GE, %115, %c : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %117 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %118 = stablehlo.select %116, %117, %cst : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %119 = stablehlo.convert %118 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %120 = stablehlo.broadcast_in_dim %48, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %121 = stablehlo.compare  GT, %113, %120 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %122 = stablehlo.convert %121 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %123 = stablehlo.multiply %119, %122 : tensor<7x1024xf32>
    %124 = stablehlo.convert %123 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %125 = stablehlo.reshape %124 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.add %112, %126 : tensor<1x24x7x1024xbf16>
    %128 = stablehlo.convert %127 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %129 = stablehlo.reduce(%128 init: %cst_3) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %131 = stablehlo.subtract %128, %130 : tensor<1x24x7x1024xf32>
    %132 = stablehlo.exponential %131 : tensor<1x24x7x1024xf32>
    %133 = stablehlo.reduce(%132 init: %cst_6) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %134 = stablehlo.broadcast_in_dim %133, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %135 = stablehlo.divide %132, %134 : tensor<1x24x7x1024xf32>
    %136 = stablehlo.convert %135 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %137 = stablehlo.reshape %136 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %138 = stablehlo.custom_call @tt.mark_argument(%arg11) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %139 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %140 = stablehlo.custom_call @tt.mark_argument(%139) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %142 = stablehlo.transpose %141, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %143 = stablehlo.dot_general %34, %142, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %144 = stablehlo.reshape %143 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %145 = stablehlo.transpose %144, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %146 = "stablehlo.scatter"(%138, %81, %145) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %147 = stablehlo.broadcast_in_dim %146, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %148 = stablehlo.reshape %147 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %149 = stablehlo.dot_general %137, %148, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %150 = stablehlo.reshape %149 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %151 = stablehlo.transpose %150, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %153 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %154 = stablehlo.custom_call @tt.mark_argument(%153) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %156 = stablehlo.transpose %155, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %157 = stablehlo.dot_general %152, %156, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %158 = stablehlo.reshape %157 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %159 = stablehlo.add %13, %158 : tensor<1x7x3072xbf16>
    %160 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %161 = stablehlo.custom_call @tt.mark_argument(%160) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %162 = stablehlo.reshape %161 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %163 = stablehlo.convert %162 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %164 = stablehlo.broadcast_in_dim %163, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %165 = stablehlo.convert %159 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %166 = stablehlo.power %165, %cst_2 : tensor<1x7x3072xf32>
    %167 = stablehlo.reduce(%166 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %168 = stablehlo.multiply %167, %cst_1 : tensor<1x7xf32>
    %169 = stablehlo.reshape %168 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %170 = stablehlo.add %169, %24 : tensor<1x7x1xf32>
    %171 = stablehlo.rsqrt %170 : tensor<1x7x1xf32>
    %172 = stablehlo.reshape %171 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %173 = stablehlo.broadcast_in_dim %172, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %174 = stablehlo.multiply %165, %173 : tensor<1x7x3072xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %177 = stablehlo.multiply %164, %176 : tensor<1x7x3072xf32>
    %178 = stablehlo.convert %177 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %179 = stablehlo.reshape %178 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %180 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %181 = stablehlo.custom_call @tt.mark_argument(%180) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %182 = stablehlo.reshape %181 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %184 = stablehlo.dot_general %179, %183, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %186 = stablehlo.convert %185 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %187 = stablehlo.logistic %185 : tensor<1x7x8192xbf16>
    %188 = stablehlo.convert %187 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %189 = stablehlo.multiply %186, %188 : tensor<1x7x8192xf32>
    %190 = stablehlo.convert %189 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %191 = stablehlo.convert %190 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %192 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %193 = stablehlo.custom_call @tt.mark_argument(%192) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %194 = stablehlo.reshape %193 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %196 = stablehlo.dot_general %179, %195, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %197 = stablehlo.reshape %196 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %198 = stablehlo.convert %197 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %199 = stablehlo.multiply %191, %198 : tensor<1x7x8192xf32>
    %200 = stablehlo.convert %199 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %201 = stablehlo.reshape %200 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %202 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %203 = stablehlo.custom_call @tt.mark_argument(%202) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %204 = stablehlo.reshape %203 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %205 = stablehlo.transpose %204, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %206 = stablehlo.dot_general %201, %205, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %206 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %208 = stablehlo.add %159, %207 : tensor<1x7x3072xbf16>
    %209 = stablehlo.convert %208 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %210 = stablehlo.power %209, %cst_2 : tensor<1x7x3072xf32>
    %211 = stablehlo.reduce(%210 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %212 = stablehlo.multiply %211, %cst_1 : tensor<1x7xf32>
    %213 = stablehlo.reshape %212 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %214 = stablehlo.add %213, %24 : tensor<1x7x1xf32>
    %215 = stablehlo.rsqrt %214 : tensor<1x7x1xf32>
    %216 = stablehlo.reshape %215 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %217 = stablehlo.broadcast_in_dim %216, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %218 = stablehlo.multiply %209, %217 : tensor<1x7x3072xf32>
    %219 = stablehlo.convert %218 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %220 = stablehlo.convert %219 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %221 = stablehlo.multiply %4, %220 : tensor<1x7x3072xf32>
    %222 = stablehlo.convert %221 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %223 = stablehlo.reshape %222 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %224 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %225 = stablehlo.custom_call @tt.mark_argument(%224) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %226 = stablehlo.reshape %225 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %227 = stablehlo.transpose %226, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %228 = stablehlo.dot_general %223, %227, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %229 = stablehlo.reshape %228 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %229 : tensor<1x7x128256xbf16>
  }
}
2025-09-08 14:24:53.576 (   7.249s) [        6D2F5000]      module_builder.cc:187      1| SHLO Module after frontend StableHLO pipeline:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<7x1024xbf16>
    %c = stablehlo.constant dense<1> : tensor<7x1024xi64>
    %c_0 = stablehlo.constant dense<0> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<1x7x3072xf32>
    %cst_3 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %c_4 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<"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tensor<1024xi64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %2 = stablehlo.convert %1 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %4 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %5 = stablehlo.reshape %4 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %6 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %7 = stablehlo.reshape %6 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %8 = stablehlo.convert %7 : (tensor<7xi64>) -> tensor<7xui32>
    %9 = "stablehlo.gather"(%5, %8) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %10 = stablehlo.reshape %9 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %11 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.reshape %11 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %13 = stablehlo.convert %12 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %14 = stablehlo.broadcast_in_dim %13, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %15 = stablehlo.convert %10 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %16 = stablehlo.power %15, %cst_2 : tensor<1x7x3072xf32>
    %17 = stablehlo.reduce(%16 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %18 = stablehlo.multiply %17, %cst_1 : tensor<1x7xf32>
    %19 = stablehlo.reshape %18 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %20 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %21 = stablehlo.add %19, %20 : tensor<1x7x1xf32>
    %22 = stablehlo.rsqrt %21 : tensor<1x7x1xf32>
    %23 = stablehlo.reshape %22 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %24 = stablehlo.broadcast_in_dim %23, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %25 = stablehlo.multiply %15, %24 : tensor<1x7x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %27 = stablehlo.convert %26 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %14, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %31 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %32 = stablehlo.reshape %31 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %33 = stablehlo.transpose %32, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %34 = stablehlo.dot_general %30, %33, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %36 = stablehlo.transpose %35, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %37 = stablehlo.convert %36 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %38 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %39 = stablehlo.reshape %38 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %40 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %41 = stablehlo.reshape %40 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %42 = stablehlo.convert %40 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %43 = stablehlo.dot_general %39, %42, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %44 = stablehlo.transpose %43, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %45 = stablehlo.concatenate %44, %44, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %46 = stablehlo.cosine %45 : tensor<1x7x128xf32>
    %47 = stablehlo.convert %46 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %48 = stablehlo.reshape %47 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %49 = stablehlo.convert %48 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %50 = stablehlo.reshape %49 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %51 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %52 = stablehlo.multiply %37, %51 : tensor<1x24x7x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %54 = stablehlo.slice %36 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %55 = stablehlo.negate %54 : tensor<1x24x7x64xbf16>
    %56 = stablehlo.slice %36 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %58 = stablehlo.convert %57 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %59 = stablehlo.sine %45 : tensor<1x7x128xf32>
    %60 = stablehlo.convert %59 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %61 = stablehlo.reshape %60 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %63 = stablehlo.reshape %62 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %65 = stablehlo.multiply %58, %64 : tensor<1x24x7x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %67 = stablehlo.add %53, %66 : tensor<1x24x7x128xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %69 = stablehlo.compare  LT, %41, %c_0 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %70 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %71 = stablehlo.add %41, %70 : tensor<7xi64>
    %72 = stablehlo.select %69, %71, %41 : tensor<7xi1>, tensor<7xi64>
    %73 = stablehlo.reshape %72 : (tensor<7xi64>) -> tensor<7x1xi64>
    %74 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %77 = stablehlo.dot_general %30, %76, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %78 = stablehlo.reshape %77 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %80 = stablehlo.convert %79 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %82 = stablehlo.multiply %80, %81 : tensor<1x8x7x128xf32>
    %83 = stablehlo.convert %82 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %84 = stablehlo.slice %79 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %85 = stablehlo.negate %84 : tensor<1x8x7x64xbf16>
    %86 = stablehlo.slice %79 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %87 = stablehlo.concatenate %85, %86, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %88 = stablehlo.convert %87 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x8x7x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %92 = stablehlo.add %83, %91 : tensor<1x8x7x128xbf16>
    %93 = "stablehlo.scatter"(%arg16, %73, %92) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %94 = stablehlo.broadcast_in_dim %93, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %96 = stablehlo.transpose %95, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %97 = stablehlo.reshape %96 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %98 = stablehlo.dot_general %68, %97, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %100 = stablehlo.convert %99 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<1x24x7x1024xf32>
    %103 = stablehlo.convert %102 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %104 = stablehlo.broadcast_in_dim %c_5, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.broadcast_in_dim %c_4, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %106 = stablehlo.subtract %104, %105 : tensor<7x1024xi64>
    %107 = stablehlo.compare  GE, %106, %c : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %108 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %109 = stablehlo.select %107, %108, %cst : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %110 = stablehlo.convert %109 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %111 = stablehlo.broadcast_in_dim %41, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %112 = stablehlo.compare  GT, %104, %111 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %113 = stablehlo.convert %112 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %114 = stablehlo.multiply %110, %113 : tensor<7x1024xf32>
    %115 = stablehlo.convert %114 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %116 = stablehlo.reshape %115 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %118 = stablehlo.add %103, %117 : tensor<1x24x7x1024xbf16>
    %119 = stablehlo.convert %118 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %120 = stablehlo.reduce(%119 init: %cst_3) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %122 = stablehlo.subtract %119, %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.exponential %122 : tensor<1x24x7x1024xf32>
    %124 = stablehlo.reduce(%123 init: %cst_6) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %126 = stablehlo.divide %123, %125 : tensor<1x24x7x1024xf32>
    %127 = stablehlo.convert %126 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %129 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %130 = stablehlo.reshape %129 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %131 = stablehlo.transpose %130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %132 = stablehlo.dot_general %30, %131, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %133 = stablehlo.reshape %132 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %135 = "stablehlo.scatter"(%arg11, %73, %134) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %137 = stablehlo.reshape %136 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %138 = stablehlo.dot_general %128, %137, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %139 = stablehlo.reshape %138 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %140 = stablehlo.transpose %139, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %142 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %143 = stablehlo.reshape %142 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.transpose %143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %145 = stablehlo.dot_general %141, %144, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %146 = stablehlo.reshape %145 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %147 = stablehlo.add %10, %146 : tensor<1x7x3072xbf16>
    %148 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %150 = stablehlo.convert %149 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %151 = stablehlo.broadcast_in_dim %150, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.convert %147 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %153 = stablehlo.power %152, %cst_2 : tensor<1x7x3072xf32>
    %154 = stablehlo.reduce(%153 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %155 = stablehlo.multiply %154, %cst_1 : tensor<1x7xf32>
    %156 = stablehlo.reshape %155 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %157 = stablehlo.add %156, %20 : tensor<1x7x1xf32>
    %158 = stablehlo.rsqrt %157 : tensor<1x7x1xf32>
    %159 = stablehlo.reshape %158 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %161 = stablehlo.multiply %152, %160 : tensor<1x7x3072xf32>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %163 = stablehlo.convert %162 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %164 = stablehlo.multiply %151, %163 : tensor<1x7x3072xf32>
    %165 = stablehlo.convert %164 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %166 = stablehlo.reshape %165 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %167 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %168 = stablehlo.reshape %167 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %170 = stablehlo.dot_general %166, %169, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %171 = stablehlo.reshape %170 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %172 = stablehlo.convert %171 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %173 = stablehlo.logistic %171 : tensor<1x7x8192xbf16>
    %174 = stablehlo.convert %173 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %175 = stablehlo.multiply %172, %174 : tensor<1x7x8192xf32>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %177 = stablehlo.convert %176 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %178 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %179 = stablehlo.reshape %178 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %180 = stablehlo.transpose %179, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %181 = stablehlo.dot_general %166, %180, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %183 = stablehlo.convert %182 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %184 = stablehlo.multiply %177, %183 : tensor<1x7x8192xf32>
    %185 = stablehlo.convert %184 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %187 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %188 = stablehlo.reshape %187 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %190 = stablehlo.dot_general %186, %189, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %191 = stablehlo.reshape %190 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %192 = stablehlo.add %147, %191 : tensor<1x7x3072xbf16>
    %193 = stablehlo.convert %192 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %194 = stablehlo.power %193, %cst_2 : tensor<1x7x3072xf32>
    %195 = stablehlo.reduce(%194 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %196 = stablehlo.multiply %195, %cst_1 : tensor<1x7xf32>
    %197 = stablehlo.reshape %196 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %198 = stablehlo.add %197, %20 : tensor<1x7x1xf32>
    %199 = stablehlo.rsqrt %198 : tensor<1x7x1xf32>
    %200 = stablehlo.reshape %199 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %201 = stablehlo.broadcast_in_dim %200, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %202 = stablehlo.multiply %193, %201 : tensor<1x7x3072xf32>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %204 = stablehlo.convert %203 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %205 = stablehlo.multiply %3, %204 : tensor<1x7x3072xf32>
    %206 = stablehlo.convert %205 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %207 = stablehlo.reshape %206 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %208 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %210 = stablehlo.transpose %209, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %211 = stablehlo.dot_general %207, %210, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %212 = stablehlo.reshape %211 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %212 : tensor<1x7x128256xbf16>
  }
}
2025-09-08 14:24:53.617 (   7.290s) [        6D2F5000]      module_builder.cc:458      1| SHLO Module after compiler StableHLO pipeline:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=1]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<7x1024xbf16>
    %c = stablehlo.constant dense<1> : tensor<7x1024xi64>
    %c_0 = stablehlo.constant dense<0> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<1x7x3072xf32>
    %cst_3 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %c_4 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<"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tensor<1024xi64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %1 = stablehlo.reshape %0 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %2 = stablehlo.convert %1 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %4 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %5 = stablehlo.reshape %4 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %6 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %7 = stablehlo.reshape %6 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %8 = stablehlo.convert %7 : (tensor<7xi64>) -> tensor<7xui32>
    %9 = "stablehlo.gather"(%5, %8) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %10 = stablehlo.reshape %9 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %11 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.reshape %11 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %13 = stablehlo.convert %12 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %14 = stablehlo.broadcast_in_dim %13, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %15 = stablehlo.convert %10 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %16 = stablehlo.power %15, %cst_2 : tensor<1x7x3072xf32>
    %17 = stablehlo.reduce(%16 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %18 = stablehlo.multiply %17, %cst_1 : tensor<1x7xf32>
    %19 = stablehlo.reshape %18 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %20 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %21 = stablehlo.add %19, %20 : tensor<1x7x1xf32>
    %22 = stablehlo.rsqrt %21 : tensor<1x7x1xf32>
    %23 = stablehlo.reshape %22 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %24 = stablehlo.broadcast_in_dim %23, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %25 = stablehlo.multiply %15, %24 : tensor<1x7x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %27 = stablehlo.convert %26 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %14, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %31 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %32 = stablehlo.reshape %31 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %33 = stablehlo.transpose %32, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %34 = stablehlo.dot_general %30, %33, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %36 = stablehlo.transpose %35, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %37 = stablehlo.convert %36 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %38 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %39 = stablehlo.reshape %38 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %40 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %41 = stablehlo.reshape %40 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %42 = stablehlo.convert %40 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %43 = stablehlo.dot_general %39, %42, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %44 = stablehlo.transpose %43, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %45 = stablehlo.concatenate %44, %44, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %46 = stablehlo.cosine %45 : tensor<1x7x128xf32>
    %47 = stablehlo.convert %46 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %48 = stablehlo.reshape %47 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %49 = stablehlo.convert %48 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %50 = stablehlo.reshape %49 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %51 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %52 = stablehlo.multiply %37, %51 : tensor<1x24x7x128xf32>
    %53 = stablehlo.convert %52 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %54 = stablehlo.slice %36 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %55 = stablehlo.negate %54 : tensor<1x24x7x64xbf16>
    %56 = stablehlo.slice %36 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %57 = stablehlo.concatenate %55, %56, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %58 = stablehlo.convert %57 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %59 = stablehlo.sine %45 : tensor<1x7x128xf32>
    %60 = stablehlo.convert %59 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %61 = stablehlo.reshape %60 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %63 = stablehlo.reshape %62 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %65 = stablehlo.multiply %58, %64 : tensor<1x24x7x128xf32>
    %66 = stablehlo.convert %65 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %67 = stablehlo.add %53, %66 : tensor<1x24x7x128xbf16>
    %68 = stablehlo.reshape %67 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %69 = stablehlo.compare  LT, %41, %c_0 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %70 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %71 = stablehlo.add %41, %70 : tensor<7xi64>
    %72 = stablehlo.select %69, %71, %41 : tensor<7xi1>, tensor<7xi64>
    %73 = stablehlo.reshape %72 : (tensor<7xi64>) -> tensor<7x1xi64>
    %74 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %75 = stablehlo.reshape %74 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %77 = stablehlo.dot_general %30, %76, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %78 = stablehlo.reshape %77 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %80 = stablehlo.convert %79 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %82 = stablehlo.multiply %80, %81 : tensor<1x8x7x128xf32>
    %83 = stablehlo.convert %82 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %84 = stablehlo.slice %79 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %85 = stablehlo.negate %84 : tensor<1x8x7x64xbf16>
    %86 = stablehlo.slice %79 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %87 = stablehlo.concatenate %85, %86, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %88 = stablehlo.convert %87 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x8x7x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %92 = stablehlo.add %83, %91 : tensor<1x8x7x128xbf16>
    %93 = "stablehlo.scatter"(%arg16, %73, %92) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %94 = stablehlo.broadcast_in_dim %93, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %95 = stablehlo.reshape %94 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %96 = stablehlo.transpose %95, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %97 = stablehlo.reshape %96 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %98 = stablehlo.dot_general %68, %97, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %100 = stablehlo.convert %99 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<1x24x7x1024xf32>
    %103 = stablehlo.convert %102 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %104 = stablehlo.broadcast_in_dim %c_5, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.broadcast_in_dim %c_4, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %106 = stablehlo.subtract %104, %105 : tensor<7x1024xi64>
    %107 = stablehlo.compare  GE, %106, %c : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %108 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %109 = stablehlo.select %107, %108, %cst : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %110 = stablehlo.convert %109 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %111 = stablehlo.broadcast_in_dim %41, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %112 = stablehlo.compare  GT, %104, %111 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %113 = stablehlo.convert %112 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %114 = stablehlo.multiply %110, %113 : tensor<7x1024xf32>
    %115 = stablehlo.convert %114 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %116 = stablehlo.reshape %115 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %118 = stablehlo.add %103, %117 : tensor<1x24x7x1024xbf16>
    %119 = stablehlo.convert %118 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %120 = stablehlo.reduce(%119 init: %cst_3) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %122 = stablehlo.subtract %119, %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.exponential %122 : tensor<1x24x7x1024xf32>
    %124 = stablehlo.reduce(%123 init: %cst_6) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %126 = stablehlo.divide %123, %125 : tensor<1x24x7x1024xf32>
    %127 = stablehlo.convert %126 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %128 = stablehlo.reshape %127 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %129 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %130 = stablehlo.reshape %129 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %131 = stablehlo.transpose %130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %132 = stablehlo.dot_general %30, %131, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %133 = stablehlo.reshape %132 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %135 = "stablehlo.scatter"(%arg11, %73, %134) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %137 = stablehlo.reshape %136 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %138 = stablehlo.dot_general %128, %137, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %139 = stablehlo.reshape %138 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %140 = stablehlo.transpose %139, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %142 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %143 = stablehlo.reshape %142 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.transpose %143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %145 = stablehlo.dot_general %141, %144, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %146 = stablehlo.reshape %145 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %147 = stablehlo.add %10, %146 : tensor<1x7x3072xbf16>
    %148 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %150 = stablehlo.convert %149 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %151 = stablehlo.broadcast_in_dim %150, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.convert %147 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %153 = stablehlo.power %152, %cst_2 : tensor<1x7x3072xf32>
    %154 = stablehlo.reduce(%153 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %155 = stablehlo.multiply %154, %cst_1 : tensor<1x7xf32>
    %156 = stablehlo.reshape %155 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %157 = stablehlo.add %156, %20 : tensor<1x7x1xf32>
    %158 = stablehlo.rsqrt %157 : tensor<1x7x1xf32>
    %159 = stablehlo.reshape %158 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %161 = stablehlo.multiply %152, %160 : tensor<1x7x3072xf32>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %163 = stablehlo.convert %162 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %164 = stablehlo.multiply %151, %163 : tensor<1x7x3072xf32>
    %165 = stablehlo.convert %164 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %166 = stablehlo.reshape %165 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %167 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %168 = stablehlo.reshape %167 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %170 = stablehlo.dot_general %166, %169, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %171 = stablehlo.reshape %170 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %172 = stablehlo.convert %171 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %173 = stablehlo.logistic %171 : tensor<1x7x8192xbf16>
    %174 = stablehlo.convert %173 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %175 = stablehlo.multiply %172, %174 : tensor<1x7x8192xf32>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %177 = stablehlo.convert %176 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %178 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %179 = stablehlo.reshape %178 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %180 = stablehlo.transpose %179, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %181 = stablehlo.dot_general %166, %180, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %183 = stablehlo.convert %182 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %184 = stablehlo.multiply %177, %183 : tensor<1x7x8192xf32>
    %185 = stablehlo.convert %184 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %186 = stablehlo.reshape %185 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %187 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %188 = stablehlo.reshape %187 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %190 = stablehlo.dot_general %186, %189, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %191 = stablehlo.reshape %190 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %192 = stablehlo.add %147, %191 : tensor<1x7x3072xbf16>
    %193 = stablehlo.convert %192 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %194 = stablehlo.power %193, %cst_2 : tensor<1x7x3072xf32>
    %195 = stablehlo.reduce(%194 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %196 = stablehlo.multiply %195, %cst_1 : tensor<1x7xf32>
    %197 = stablehlo.reshape %196 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %198 = stablehlo.add %197, %20 : tensor<1x7x1xf32>
    %199 = stablehlo.rsqrt %198 : tensor<1x7x1xf32>
    %200 = stablehlo.reshape %199 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %201 = stablehlo.broadcast_in_dim %200, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %202 = stablehlo.multiply %193, %201 : tensor<1x7x3072xf32>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %204 = stablehlo.convert %203 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %205 = stablehlo.multiply %3, %204 : tensor<1x7x3072xf32>
    %206 = stablehlo.convert %205 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %207 = stablehlo.reshape %206 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %208 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %210 = stablehlo.transpose %209, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %211 = stablehlo.dot_general %207, %210, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %212 = stablehlo.reshape %211 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %212 : tensor<1x7x128256xbf16>
  }
}
2025-09-08 14:24:53.627 (   7.300s) [        6D2F5000]      module_builder.cc:480      1| TTIR Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>} {
  func.func @main(%arg0: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<7x1024xbf16>}> : () -> tensor<7x1024xbf16>
    %1 = "ttir.constant"() <{value = dense<1> : tensor<7x1024xi64>}> : () -> tensor<7x1024xi64>
    %2 = "ttir.constant"() <{value = dense<0> : tensor<7xi64>}> : () -> tensor<7xi64>
    %3 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x7xf32>}> : () -> tensor<1x7xf32>
    %4 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<1x7x3072xf32>}> : () -> tensor<1x7x3072xf32>
    %5 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
    %6 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>}> : () -> tensor<7xi64>
    %7 = "ttir.constant"() <{value = dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000880000000000000089000000000000008A000000000000008B000000000000008C000000000000008D000000000000008E000000000000008F0000000000000090000000000000009100000000000000920000000000000093000000000000009400000000000000950000000000000096000000000000009700000000000000980000000000000099000000000000009A000000000000009B000000000000009C000000000000009D000000000000009E000000000000009F00000000000000A000000000000000A100000000000000A200000000000000A300000000000000A400000000000000A500000000000000A600000000000000A700000000000000A800000000000000A900000000000000AA00000000000000AB00000000000000AC00000000000000AD00000000000000AE00000000000000AF00000000000000B000000000000000B100000000000000B200000000000000B300000000000000B400000000000000B500000000000000B600000000000000B700000000000000B800000000000000B900000000000000BA00000000000000BB00000000000000BC00000000000000BD00000000000000BE00000000000000BF00000000000000C000000000000000C100000000000000C200000000000000C300000000000000C400000000000000C500000000000000C600000000000000C700000000000000C800000000000000C900000000000000CA00000000000000CB00000000000000CC00000000000000CD00000000000000CE00000000000000CF00000000000000D000000000000000D100000000000000D200000000000000D300000000000000D400000000000000D500000000000000D600000000000000D700000000000000D800000000000000D900000000000000DA00000000000000DB00000000000000DC00000000000000DD00000000000000DE00000000000000DF00000000000000E000000000000000E100000000000000E200000000000000E300000000000000E400000000000000E500000000000000E600000000000000E700000000000000E800000000000000E900000000000000EA00000000000000EB00000000000000EC00000000000000ED00000000000000EE00000000000000EF00000000000000F000000000000000F100000000000000F200000000000000F300000000000000F400000000000000F500000000000000F600000000000000F700000000000000F800000000000000F900000000000000FA00000000000000FB00000000000000FC00000000000000FD00000000000000FE00000000000000FF0000000000000000010000000000000101000000000000020100000000000003010000000000000401000000000000050100000000000006010000000000000701000000000000080100000000000009010000000000000A010000000000000B010000000000000C010000000000000D010000000000000E010000000000000F0100000000000010010000000000001101000000000000120100000000000013010000000000001401000000000000150100000000000016010000000000001701000000000000180100000000000019010000000000001A010000000000001B010000000000001C010000000000001D010000000000001E010000000000001F0100000000000020010000000000002101000000000000220100000000000023010000000000002401000000000000250100000000000026010000000000002701000000000000280100000000000029010000000000002A010000000000002B010000000000002C010000000000002D010000000000002E010000000000002F0100000000000030010000000000003101000000000000320100000000000033010000000000003401000000000000350100000000000036010000000000003701000000000000380100000000000039010000000000003A010000000000003B010000000000003C010000000000003D010000000000003E010000000000003F0100000000000040010000000000004101000000000000420100000000000043010000000000004401000000000000450100000000000046010000000000004701000000000000480100000000000049010000000000004A010000000000004B010000000000004C010000000000004D010000000000004E010000000000004F0100000000000050010000000000005101000000000000520100000000000053010000000000005401000000000000550100000000000056010000000000005701000000000000580100000000000059010000000000005A010000000000005B010000000000005C010000000000005D010000000000005E010000000000005F0100000000000060010000000000006101000000000000620100000000000063010000000000006401000000000000650100000000000066010000000000006701000000000000680100000000000069010000000000006A010000000000006B010000000000006C010000000000006D010000000000006E010000000000006F0100000000000070010000000000007101000000000000720100000000000073010000000000007401000000000000750100000000000076010000000000007701000000000000780100000000000079010000000000007A010000000000007B010000000000007C010000000000007D010000000000007E010000000000007F0100000000000080010000000000008101000000000000820100000000000083010000000000008401000000000000850100000000000086010000000000008701000000000000880100000000000089010000000000008A010000000000008B010000000000008C010000000000008D010000000000008E010000000000008F0100000000000090010000000000009101000000000000920100000000000093010000000000009401000000000000950100000000000096010000000000009701000000000000980100000000000099010000000000009A010000000000009B010000000000009C010000000000009D010000000000009E010000000000009F01000000000000A001000000000000A101000000000000A201000000000000A301000000000000A401000000000000A501000000000000A601000000000000A701000000000000A801000000000000A901000000000000AA01000000000000AB01000000000000AC01000000000000AD01000000000000AE01000000000000AF01000000000000B001000000000000B101000000000000B201000000000000B301000000000000B401000000000000B501000000000000B601000000000000B701000000000000B801000000000000B901000000000000BA01000000000000BB01000000000000BC01000000000000BD01000000000000BE01000000000000BF01000000000000C001000000000000C101000000000000C201000000000000C301000000000000C401000000000000C501000000000000C601000000000000C701000000000000C801000000000000C901000000000000CA01000000000000CB01000000000000CC01000000000000CD01000000000000CE01000000000000CF01000000000000D001000000000000D101000000000000D201000000000000D301000000000000D401000000000000D501000000000000D601000000000000D701000000000000D801000000000000D901000000000000DA01000000000000DB01000000000000DC01000000000000DD01000000000000DE01000000000000DF01000000000000E001000000000000E101000000000000E201000000000000E301000000000000E401000000000000E501000000000000E601000000000000E701000000000000E801000000000000E901000000000000EA01000000000000EB01000000000000EC01000000000000ED01000000000000EE01000000000000EF01000000000000F001000000000000F101000000000000F201000000000000F301000000000000F401000000000000F501000000000000F601000000000000F701000000000000F801000000000000F901000000000000FA01000000000000FB01000000000000FC01000000000000FD01000000000000FE01000000000000FF0100000000000000020000000000000102000000000000020200000000000003020000000000000402000000000000050200000000000006020000000000000702000000000000080200000000000009020000000000000A020000000000000B020000000000000C020000000000000D020000000000000E020000000000000F0200000000000010020000000000001102000000000000120200000000000013020000000000001402000000000000150200000000000016020000000000001702000000000000180200000000000019020000000000001A020000000000001B020000000000001C020000000000001D020000000000001E020000000000001F0200000000000020020000000000002102000000000000220200000000000023020000000000002402000000000000250200000000000026020000000000002702000000000000280200000000000029020000000000002A020000000000002B020000000000002C020000000000002D020000000000002E020000000000002F0200000000000030020000000000003102000000000000320200000000000033020000000000003402000000000000350200000000000036020000000000003702000000000000380200000000000039020000000000003A020000000000003B020000000000003C020000000000003D020000000000003E020000000000003F0200000000000040020000000000004102000000000000420200000000000043020000000000004402000000000000450200000000000046020000000000004702000000000000480200000000000049020000000000004A020000000000004B020000000000004C020000000000004D020000000000004E020000000000004F0200000000000050020000000000005102000000000000520200000000000053020000000000005402000000000000550200000000000056020000000000005702000000000000580200000000000059020000000000005A020000000000005B020000000000005C020000000000005D020000000000005E020000000000005F0200000000000060020000000000006102000000000000620200000000000063020000000000006402000000000000650200000000000066020000000000006702000000000000680200000000000069020000000000006A020000000000006B020000000000006C020000000000006D020000000000006E020000000000006F0200000000000070020000000000007102000000000000720200000000000073020000000000007402000000000000750200000000000076020000000000007702000000000000780200000000000079020000000000007A020000000000007B020000000000007C020000000000007D020000000000007E020000000000007F0200000000000080020000000000008102000000000000820200000000000083020000000000008402000000000000850200000000000086020000000000008702000000000000880200000000000089020000000000008A020000000000008B020000000000008C020000000000008D020000000000008E020000000000008F0200000000000090020000000000009102000000000000920200000000000093020000000000009402000000000000950200000000000096020000000000009702000000000000980200000000000099020000000000009A020000000000009B020000000000009C020000000000009D020000000000009E020000000000009F02000000000000A002000000000000A102000000000000A202000000000000A302000000000000A402000000000000A502000000000000A602000000000000A702000000000000A802000000000000A902000000000000AA02000000000000AB02000000000000AC02000000000000AD02000000000000AE02000000000000AF02000000000000B002000000000000B102000000000000B202000000000000B302000000000000B402000000000000B502000000000000B602000000000000B702000000000000B802000000000000B902000000000000BA02000000000000BB02000000000000BC02000000000000BD02000000000000BE02000000000000BF02000000000000C002000000000000C102000000000000C202000000000000C302000000000000C402000000000000C502000000000000C602000000000000C702000000000000C802000000000000C902000000000000CA02000000000000CB02000000000000CC02000000000000CD02000000000000CE02000000000000CF02000000000000D002000000000000D102000000000000D202000000000000D302000000000000D402000000000000D502000000000000D602000000000000D702000000000000D802000000000000D902000000000000DA02000000000000DB02000000000000DC02000000000000DD02000000000000DE02000000000000DF02000000000000E002000000000000E102000000000000E202000000000000E302000000000000E402000000000000E502000000000000E602000000000000E702000000000000E802000000000000E902000000000000EA02000000000000EB02000000000000EC02000000000000ED02000000000000EE02000000000000EF02000000000000F002000000000000F102000000000000F202000000000000F302000000000000F402000000000000F502000000000000F602000000000000F702000000000000F802000000000000F902000000000000FA02000000000000FB02000000000000FC02000000000000FD02000000000000FE02000000000000FF0200000000000000030000000000000103000000000000020300000000000003030000000000000403000000000000050300000000000006030000000000000703000000000000080300000000000009030000000000000A030000000000000B030000000000000C030000000000000D030000000000000E030000000000000F0300000000000010030000000000001103000000000000120300000000000013030000000000001403000000000000150300000000000016030000000000001703000000000000180300000000000019030000000000001A030000000000001B030000000000001C030000000000001D030000000000001E030000000000001F0300000000000020030000000000002103000000000000220300000000000023030000000000002403000000000000250300000000000026030000000000002703000000000000280300000000000029030000000000002A030000000000002B030000000000002C030000000000002D030000000000002E030000000000002F0300000000000030030000000000003103000000000000320300000000000033030000000000003403000000000000350300000000000036030000000000003703000000000000380300000000000039030000000000003A030000000000003B030000000000003C030000000000003D030000000000003E030000000000003F0300000000000040030000000000004103000000000000420300000000000043030000000000004403000000000000450300000000000046030000000000004703000000000000480300000000000049030000000000004A030000000000004B030000000000004C030000000000004D030000000000004E030000000000004F0300000000000050030000000000005103000000000000520300000000000053030000000000005403000000000000550300000000000056030000000000005703000000000000580300000000000059030000000000005A030000000000005B030000000000005C030000000000005D030000000000005E030000000000005F0300000000000060030000000000006103000000000000620300000000000063030000000000006403000000000000650300000000000066030000000000006703000000000000680300000000000069030000000000006A030000000000006B030000000000006C030000000000006D030000000000006E030000000000006F0300000000000070030000000000007103000000000000720300000000000073030000000000007403000000000000750300000000000076030000000000007703000000000000780300000000000079030000000000007A030000000000007B030000000000007C030000000000007D030000000000007E030000000000007F0300000000000080030000000000008103000000000000820300000000000083030000000000008403000000000000850300000000000086030000000000008703000000000000880300000000000089030000000000008A030000000000008B030000000000008C030000000000008D030000000000008E030000000000008F0300000000000090030000000000009103000000000000920300000000000093030000000000009403000000000000950300000000000096030000000000009703000000000000980300000000000099030000000000009A030000000000009B030000000000009C030000000000009D030000000000009E030000000000009F03000000000000A003000000000000A103000000000000A203000000000000A303000000000000A403000000000000A503000000000000A603000000000000A703000000000000A803000000000000A903000000000000AA03000000000000AB03000000000000AC03000000000000AD03000000000000AE03000000000000AF03000000000000B003000000000000B103000000000000B203000000000000B303000000000000B403000000000000B503000000000000B603000000000000B703000000000000B803000000000000B903000000000000BA03000000000000BB03000000000000BC03000000000000BD03000000000000BE03000000000000BF03000000000000C003000000000000C103000000000000C203000000000000C303000000000000C403000000000000C503000000000000C603000000000000C703000000000000C803000000000000C903000000000000CA03000000000000CB03000000000000CC03000000000000CD03000000000000CE03000000000000CF03000000000000D003000000000000D103000000000000D203000000000000D303000000000000D403000000000000D503000000000000D603000000000000D703000000000000D803000000000000D903000000000000DA03000000000000DB03000000000000DC03000000000000DD03000000000000DE03000000000000DF03000000000000E003000000000000E103000000000000E203000000000000E303000000000000E403000000000000E503000000000000E603000000000000E703000000000000E803000000000000E903000000000000EA03000000000000EB03000000000000EC03000000000000ED03000000000000EE03000000000000EF03000000000000F003000000000000F103000000000000F203000000000000F303000000000000F403000000000000F503000000000000F603000000000000F703000000000000F803000000000000F903000000000000FA03000000000000FB03000000000000FC03000000000000FD03000000000000FE03000000000000FF03000000000000"> : tensor<1024xi64>}> : () -> tensor<1024xi64>
    %8 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %9 = ttir.empty() : tensor<1x1x3072xbf16>
    %10 = "ttir.reshape"(%arg20, %9) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %11 = ttir.empty() : tensor<3072xbf16>
    %12 = "ttir.reshape"(%10, %11) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %13 = ttir.empty() : tensor<3072xf32>
    %14 = "ttir.typecast"(%12, %13) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %15 = ttir.empty() : tensor<1x1x3072xf32>
    %16 = "ttir.reshape"(%14, %15) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %17 = ttir.empty() : tensor<1x7x3072xf32>
    %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %19 = ttir.empty() : tensor<1x128256x3072xbf16>
    %20 = "ttir.reshape"(%arg7, %19) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %21 = ttir.empty() : tensor<128256x3072xbf16>
    %22 = "ttir.reshape"(%20, %21) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %23 = ttir.empty() : tensor<1x1x7xi64>
    %24 = "ttir.reshape"(%arg6, %23) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<1x7xi64>, tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %25 = ttir.empty() : tensor<7xi64>
    %26 = "ttir.reshape"(%24, %25) <{shape = [7 : i32]}> : (tensor<1x1x7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %27 = ttir.empty() : tensor<7xui32>
    %28 = "ttir.typecast"(%26, %27) <{conservative_folding = false}> : (tensor<7xi64>, tensor<7xui32>) -> tensor<7xui32>
    %29 = ttir.empty() : tensor<7x3072xbf16>
    %30 = "ttir.gather"(%22, %28, %29) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<128256x3072xbf16>, tensor<7xui32>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %31 = ttir.empty() : tensor<1x7x3072xbf16>
    %32 = "ttir.reshape"(%30, %31) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %33 = ttir.empty() : tensor<1x1x3072xbf16>
    %34 = "ttir.reshape"(%arg8, %33) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %35 = ttir.empty() : tensor<3072xbf16>
    %36 = "ttir.reshape"(%34, %35) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %37 = ttir.empty() : tensor<3072xf32>
    %38 = "ttir.typecast"(%36, %37) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %39 = ttir.empty() : tensor<1x1x3072xf32>
    %40 = "ttir.reshape"(%38, %39) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %41 = ttir.empty() : tensor<1x7x3072xf32>
    %42 = "ttir.broadcast"(%40, %41) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %43 = ttir.empty() : tensor<1x7x3072xf32>
    %44 = "ttir.typecast"(%32, %43) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %45 = ttir.empty() : tensor<1x7x3072xf32>
    %46 = "ttir.pow"(%44, %4, %45) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %47 = ttir.empty() : tensor<1x7xf32>
    %48 = "ttir.sum"(%46, %47) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %49 = ttir.empty() : tensor<1x7xf32>
    %50 = "ttir.multiply"(%48, %3, %49) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %51 = ttir.empty() : tensor<1x7x1xf32>
    %52 = "ttir.reshape"(%50, %51) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %53 = ttir.empty() : tensor<1x1x1xf32>
    %54 = "ttir.reshape"(%arg1, %53) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %55 = ttir.empty() : tensor<1x7x1xf32>
    %56 = "ttir.broadcast"(%54, %55) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %57 = ttir.empty() : tensor<1x7x1xf32>
    %58 = "ttir.add"(%52, %56, %57) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %59 = ttir.empty() : tensor<1x7x1xf32>
    %60 = "ttir.rsqrt"(%58, %59) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %61 = ttir.empty() : tensor<1x7xf32>
    %62 = "ttir.reshape"(%60, %61) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %63 = ttir.empty() : tensor<1x7x1xf32>
    %64 = "ttir.reshape"(%62, %63) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %65 = ttir.empty() : tensor<1x7x3072xf32>
    %66 = "ttir.broadcast"(%64, %65) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %67 = ttir.empty() : tensor<1x7x3072xf32>
    %68 = "ttir.multiply"(%44, %66, %67) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %69 = ttir.empty() : tensor<1x7x3072xbf16>
    %70 = "ttir.typecast"(%68, %69) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %71 = ttir.empty() : tensor<1x7x3072xf32>
    %72 = "ttir.typecast"(%70, %71) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %73 = ttir.empty() : tensor<1x7x3072xf32>
    %74 = "ttir.multiply"(%42, %72, %73) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %75 = ttir.empty() : tensor<1x7x3072xbf16>
    %76 = "ttir.typecast"(%74, %75) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %77 = ttir.empty() : tensor<7x3072xbf16>
    %78 = "ttir.reshape"(%76, %77) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %79 = ttir.empty() : tensor<1x3072x3072xbf16>
    %80 = "ttir.reshape"(%arg17, %79) <{shape = [1 : i32, 3072 : i32, 3072 : i32]}> : (tensor<3072x3072xbf16>, tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %81 = ttir.empty() : tensor<3072x3072xbf16>
    %82 = "ttir.reshape"(%80, %81) <{shape = [3072 : i32, 3072 : i32]}> : (tensor<1x3072x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %83 = ttir.empty() : tensor<3072x3072xbf16>
    %84 = "ttir.permute"(%82, %83) <{permutation = array<i64: 1, 0>}> : (tensor<3072x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %85 = "ttir.dot_general"(%78, %84) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %86 = ttir.empty() : tensor<1x7x24x128xbf16>
    %87 = "ttir.reshape"(%85, %86) <{shape = [1 : i32, 7 : i32, 24 : i32, 128 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x24x128xbf16>) -> tensor<1x7x24x128xbf16>
    %88 = ttir.empty() : tensor<1x24x7x128xbf16>
    %89 = "ttir.permute"(%87, %88) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x24x128xbf16>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %90 = ttir.empty() : tensor<1x24x7x128xf32>
    %91 = "ttir.typecast"(%89, %90) <{conservative_folding = false}> : (tensor<1x24x7x128xbf16>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %92 = ttir.empty() : tensor<1x1x64xf32>
    %93 = "ttir.reshape"(%arg14, %92) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %94 = ttir.empty() : tensor<1x64x1xf32>
    %95 = "ttir.reshape"(%93, %94) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32>
    %96 = ttir.empty() : tensor<1x1x7xi64>
    %97 = "ttir.reshape"(%arg9, %96) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xi64>, tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %98 = ttir.empty() : tensor<7xi64>
    %99 = "ttir.reshape"(%97, %98) <{shape = [7 : i32]}> : (tensor<1x1x7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %100 = ttir.empty() : tensor<1x1x7xf32>
    %101 = "ttir.typecast"(%97, %100) <{conservative_folding = false}> : (tensor<1x1x7xi64>, tensor<1x1x7xf32>) -> tensor<1x1x7xf32>
    %102 = "ttir.dot_general"(%95, %101) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %103 = ttir.empty() : tensor<1x7x64xf32>
    %104 = "ttir.permute"(%102, %103) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32>, tensor<1x7x64xf32>) -> tensor<1x7x64xf32>
    %105 = ttir.empty() : tensor<1x7x128xf32>
    %106 = "ttir.concat"(%104, %104, %105) <{dim = 2 : si32}> : (tensor<1x7x64xf32>, tensor<1x7x64xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %107 = ttir.empty() : tensor<1x7x128xf32>
    %108 = "ttir.cos"(%106, %107) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %109 = ttir.empty() : tensor<1x7x128xbf16>
    %110 = "ttir.typecast"(%108, %109) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %111 = ttir.empty() : tensor<1x1x7x128xbf16>
    %112 = "ttir.reshape"(%110, %111) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %113 = ttir.empty() : tensor<1x1x7x128xf32>
    %114 = "ttir.typecast"(%112, %113) <{conservative_folding = false}> : (tensor<1x1x7x128xbf16>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %115 = ttir.empty() : tensor<1x7x128xf32>
    %116 = "ttir.reshape"(%114, %115) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %117 = ttir.empty() : tensor<1x1x7x128xf32>
    %118 = "ttir.reshape"(%116, %117) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %119 = ttir.empty() : tensor<1x24x7x128xf32>
    %120 = "ttir.broadcast"(%118, %119) <{broadcast_dimensions = array<i64: 1, 24, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %121 = ttir.empty() : tensor<1x24x7x128xf32>
    %122 = "ttir.multiply"(%91, %120, %121) : (tensor<1x24x7x128xf32>, tensor<1x24x7x128xf32>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %123 = ttir.empty() : tensor<1x24x7x128xbf16>
    %124 = "ttir.typecast"(%122, %123) <{conservative_folding = false}> : (tensor<1x24x7x128xf32>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %125 = ttir.empty() : tensor<1x24x7x64xbf16>
    %126 = "ttir.slice_static"(%89, %125) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 24 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x24x7x128xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x64xbf16>
    %127 = ttir.empty() : tensor<1x24x7x64xbf16>
    %128 = "ttir.neg"(%126, %127) : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x64xbf16>
    %129 = ttir.empty() : tensor<1x24x7x64xbf16>
    %130 = "ttir.slice_static"(%89, %129) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 24 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x24x7x128xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x64xbf16>
    %131 = ttir.empty() : tensor<1x24x7x128xbf16>
    %132 = "ttir.concat"(%128, %130, %131) <{dim = 3 : si32}> : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %133 = ttir.empty() : tensor<1x24x7x128xf32>
    %134 = "ttir.typecast"(%132, %133) <{conservative_folding = false}> : (tensor<1x24x7x128xbf16>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %135 = ttir.empty() : tensor<1x7x128xf32>
    %136 = "ttir.sin"(%106, %135) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %137 = ttir.empty() : tensor<1x7x128xbf16>
    %138 = "ttir.typecast"(%136, %137) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %139 = ttir.empty() : tensor<1x1x7x128xbf16>
    %140 = "ttir.reshape"(%138, %139) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %141 = ttir.empty() : tensor<1x1x7x128xf32>
    %142 = "ttir.typecast"(%140, %141) <{conservative_folding = false}> : (tensor<1x1x7x128xbf16>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %143 = ttir.empty() : tensor<1x7x128xf32>
    %144 = "ttir.reshape"(%142, %143) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %145 = ttir.empty() : tensor<1x1x7x128xf32>
    %146 = "ttir.reshape"(%144, %145) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %147 = ttir.empty() : tensor<1x24x7x128xf32>
    %148 = "ttir.broadcast"(%146, %147) <{broadcast_dimensions = array<i64: 1, 24, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %149 = ttir.empty() : tensor<1x24x7x128xf32>
    %150 = "ttir.multiply"(%134, %148, %149) : (tensor<1x24x7x128xf32>, tensor<1x24x7x128xf32>, tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %151 = ttir.empty() : tensor<1x24x7x128xbf16>
    %152 = "ttir.typecast"(%150, %151) <{conservative_folding = false}> : (tensor<1x24x7x128xf32>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %153 = ttir.empty() : tensor<1x24x7x128xbf16>
    %154 = "ttir.add"(%124, %152, %153) : (tensor<1x24x7x128xbf16>, tensor<1x24x7x128xbf16>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %155 = ttir.empty() : tensor<24x7x128xbf16>
    %156 = "ttir.reshape"(%154, %155) <{shape = [24 : i32, 7 : i32, 128 : i32]}> : (tensor<1x24x7x128xbf16>, tensor<24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %157 = ttir.empty() : tensor<7xi1>
    %158 = "ttir.lt"(%99, %2, %157) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi1>) -> tensor<7xi1>
    %159 = ttir.empty() : tensor<1xi64>
    %160 = "ttir.reshape"(%arg10, %159) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %161 = ttir.empty() : tensor<7xi64>
    %162 = "ttir.broadcast"(%160, %161) <{broadcast_dimensions = array<i64: 7>}> : (tensor<1xi64>, tensor<7xi64>) -> tensor<7xi64>
    %163 = ttir.empty() : tensor<7xi64>
    %164 = "ttir.add"(%99, %162, %163) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %165 = ttir.empty() : tensor<7xi64>
    %166 = "ttir.where"(%158, %164, %99, %165) : (tensor<7xi1>, tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %167 = ttir.empty() : tensor<7x1xi64>
    %168 = "ttir.reshape"(%166, %167) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %169 = ttir.empty() : tensor<1x1024x3072xbf16>
    %170 = "ttir.reshape"(%arg15, %169) <{shape = [1 : i32, 1024 : i32, 3072 : i32]}> : (tensor<1024x3072xbf16>, tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %171 = ttir.empty() : tensor<1024x3072xbf16>
    %172 = "ttir.reshape"(%170, %171) <{shape = [1024 : i32, 3072 : i32]}> : (tensor<1x1024x3072xbf16>, tensor<1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %173 = ttir.empty() : tensor<3072x1024xbf16>
    %174 = "ttir.permute"(%172, %173) <{permutation = array<i64: 1, 0>}> : (tensor<1024x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<3072x1024xbf16>
    %175 = "ttir.dot_general"(%78, %174) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %176 = ttir.empty() : tensor<1x7x8x128xbf16>
    %177 = "ttir.reshape"(%175, %176) <{shape = [1 : i32, 7 : i32, 8 : i32, 128 : i32]}> : (tensor<7x1024xbf16>, tensor<1x7x8x128xbf16>) -> tensor<1x7x8x128xbf16>
    %178 = ttir.empty() : tensor<1x8x7x128xbf16>
    %179 = "ttir.permute"(%177, %178) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x8x128xbf16>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %180 = ttir.empty() : tensor<1x8x7x128xf32>
    %181 = "ttir.typecast"(%179, %180) <{conservative_folding = false}> : (tensor<1x8x7x128xbf16>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %182 = ttir.empty() : tensor<1x1x7x128xf32>
    %183 = "ttir.reshape"(%116, %182) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %184 = ttir.empty() : tensor<1x8x7x128xf32>
    %185 = "ttir.broadcast"(%183, %184) <{broadcast_dimensions = array<i64: 1, 8, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %186 = ttir.empty() : tensor<1x8x7x128xf32>
    %187 = "ttir.multiply"(%181, %185, %186) : (tensor<1x8x7x128xf32>, tensor<1x8x7x128xf32>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %188 = ttir.empty() : tensor<1x8x7x128xbf16>
    %189 = "ttir.typecast"(%187, %188) <{conservative_folding = false}> : (tensor<1x8x7x128xf32>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %190 = ttir.empty() : tensor<1x8x7x64xbf16>
    %191 = "ttir.slice_static"(%179, %190) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 8 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x8x7x128xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x64xbf16>
    %192 = ttir.empty() : tensor<1x8x7x64xbf16>
    %193 = "ttir.neg"(%191, %192) : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x64xbf16>
    %194 = ttir.empty() : tensor<1x8x7x64xbf16>
    %195 = "ttir.slice_static"(%179, %194) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 8 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x8x7x128xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x64xbf16>
    %196 = ttir.empty() : tensor<1x8x7x128xbf16>
    %197 = "ttir.concat"(%193, %195, %196) <{dim = 3 : si32}> : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %198 = ttir.empty() : tensor<1x8x7x128xf32>
    %199 = "ttir.typecast"(%197, %198) <{conservative_folding = false}> : (tensor<1x8x7x128xbf16>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %200 = ttir.empty() : tensor<1x1x7x128xf32>
    %201 = "ttir.reshape"(%144, %200) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %202 = ttir.empty() : tensor<1x8x7x128xf32>
    %203 = "ttir.broadcast"(%201, %202) <{broadcast_dimensions = array<i64: 1, 8, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %204 = ttir.empty() : tensor<1x8x7x128xf32>
    %205 = "ttir.multiply"(%199, %203, %204) : (tensor<1x8x7x128xf32>, tensor<1x8x7x128xf32>, tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xf32>
    %206 = ttir.empty() : tensor<1x8x7x128xbf16>
    %207 = "ttir.typecast"(%205, %206) <{conservative_folding = false}> : (tensor<1x8x7x128xf32>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %208 = ttir.empty() : tensor<1x8x7x128xbf16>
    %209 = "ttir.add"(%189, %207, %208) : (tensor<1x8x7x128xbf16>, tensor<1x8x7x128xbf16>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %210 = ttir.empty() : tensor<1x8x1024x128xbf16>
    %211 = "ttir.scatter"(%arg16, %168, %209, %210) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>, tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %212 = ttir.empty() : tensor<1x8x1x1024x128xbf16>
    %213 = "ttir.reshape"(%211, %212) <{shape = [1 : i32, 8 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x1024x128xbf16>, tensor<1x8x1x1024x128xbf16>) -> tensor<1x8x1x1024x128xbf16>
    %214 = ttir.empty() : tensor<1x8x3x1024x128xbf16>
    %215 = "ttir.broadcast"(%213, %214) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x8x1x1024x128xbf16>, tensor<1x8x3x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %216 = ttir.empty() : tensor<1x24x1024x128xbf16>
    %217 = "ttir.reshape"(%215, %216) <{shape = [1 : i32, 24 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x3x1024x128xbf16>, tensor<1x24x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %218 = ttir.empty() : tensor<1x24x128x1024xbf16>
    %219 = "ttir.permute"(%217, %218) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x24x1024x128xbf16>, tensor<1x24x128x1024xbf16>) -> tensor<1x24x128x1024xbf16>
    %220 = ttir.empty() : tensor<24x128x1024xbf16>
    %221 = "ttir.reshape"(%219, %220) <{shape = [24 : i32, 128 : i32, 1024 : i32]}> : (tensor<1x24x128x1024xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %222 = "ttir.dot_general"(%156, %221) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %223 = ttir.empty() : tensor<1x24x7x1024xbf16>
    %224 = "ttir.reshape"(%222, %223) <{shape = [1 : i32, 24 : i32, 7 : i32, 1024 : i32]}> : (tensor<24x7x1024xbf16>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %225 = ttir.empty() : tensor<1x24x7x1024xf32>
    %226 = "ttir.typecast"(%224, %225) <{conservative_folding = false}> : (tensor<1x24x7x1024xbf16>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %227 = ttir.empty() : tensor<1x1x1x1xf32>
    %228 = "ttir.reshape"(%arg13, %227) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>
    %229 = ttir.empty() : tensor<1x24x7x1024xf32>
    %230 = "ttir.broadcast"(%228, %229) <{broadcast_dimensions = array<i64: 1, 24, 7, 1024>}> : (tensor<1x1x1x1xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %231 = ttir.empty() : tensor<1x24x7x1024xf32>
    %232 = "ttir.multiply"(%226, %230, %231) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %233 = ttir.empty() : tensor<1x24x7x1024xbf16>
    %234 = "ttir.typecast"(%232, %233) <{conservative_folding = false}> : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %235 = ttir.empty() : tensor<1x1024xi64>
    %236 = "ttir.reshape"(%7, %235) <{shape = [1 : i32, 1024 : i32]}> : (tensor<1024xi64>, tensor<1x1024xi64>) -> tensor<1x1024xi64>
    %237 = ttir.empty() : tensor<7x1024xi64>
    %238 = "ttir.broadcast"(%236, %237) <{broadcast_dimensions = array<i64: 7, 1>}> : (tensor<1x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi64>
    %239 = ttir.empty() : tensor<7x1xi64>
    %240 = "ttir.reshape"(%6, %239) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %241 = ttir.empty() : tensor<7x1024xi64>
    %242 = "ttir.broadcast"(%240, %241) <{broadcast_dimensions = array<i64: 1, 1024>}> : (tensor<7x1xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi64>
    %243 = ttir.empty() : tensor<7x1024xi64>
    %244 = "ttir.subtract"(%238, %242, %243) : (tensor<7x1024xi64>, tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi64>
    %245 = ttir.empty() : tensor<7x1024xi1>
    %246 = "ttir.ge"(%244, %1, %245) : (tensor<7x1024xi64>, tensor<7x1024xi64>, tensor<7x1024xi1>) -> tensor<7x1024xi1>
    %247 = ttir.empty() : tensor<1x1xbf16>
    %248 = "ttir.reshape"(%arg12, %247) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16>
    %249 = ttir.empty() : tensor<7x1024xbf16>
    %250 = "ttir.broadcast"(%248, %249) <{broadcast_dimensions = array<i64: 7, 1024>}> : (tensor<1x1xbf16>, tensor<7x1024xbf16>) -> tensor<7x1024xbf16>
    %251 = ttir.empty() : tensor<7x1024xbf16>
    %252 = "ttir.where"(%246, %250, %0, %251) : (tensor<7x1024xi1>, tensor<7x1024xbf16>, tensor<7x1024xbf16>, tensor<7x1024xbf16>) -> tensor<7x1024xbf16>
    %253 = ttir.empty() : tensor<7x1024xf32>
    %254 = "ttir.typecast"(%252, %253) <{conservative_folding = false}> : (tensor<7x1024xbf16>, tensor<7x1024xf32>) -> tensor<7x1024xf32>
    %255 = ttir.empty() : tensor<7x1xi64>
    %256 = "ttir.reshape"(%99, %255) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %257 = ttir.empty() : tensor<7x1024xi64>
    %258 = "ttir.broadcast"(%256, %257) <{broadcast_dimensions = array<i64: 1, 1024>}> : (tensor<7x1xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi64>
    %259 = ttir.empty() : tensor<7x1024xi1>
    %260 = "ttir.gt"(%238, %258, %259) : (tensor<7x1024xi64>, tensor<7x1024xi64>, tensor<7x1024xi1>) -> tensor<7x1024xi1>
    %261 = ttir.empty() : tensor<7x1024xf32>
    %262 = "ttir.typecast"(%260, %261) <{conservative_folding = false}> : (tensor<7x1024xi1>, tensor<7x1024xf32>) -> tensor<7x1024xf32>
    %263 = ttir.empty() : tensor<7x1024xf32>
    %264 = "ttir.multiply"(%254, %262, %263) : (tensor<7x1024xf32>, tensor<7x1024xf32>, tensor<7x1024xf32>) -> tensor<7x1024xf32>
    %265 = ttir.empty() : tensor<7x1024xbf16>
    %266 = "ttir.typecast"(%264, %265) <{conservative_folding = false}> : (tensor<7x1024xf32>, tensor<7x1024xbf16>) -> tensor<7x1024xbf16>
    %267 = ttir.empty() : tensor<1x7x1024xbf16>
    %268 = "ttir.reshape"(%266, %267) <{shape = [1 : i32, 7 : i32, 1024 : i32]}> : (tensor<7x1024xbf16>, tensor<1x7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %269 = ttir.empty() : tensor<1x1x7x1024xbf16>
    %270 = "ttir.reshape"(%268, %269) <{shape = [1 : i32, 1 : i32, 7 : i32, 1024 : i32]}> : (tensor<1x7x1024xbf16>, tensor<1x1x7x1024xbf16>) -> tensor<1x1x7x1024xbf16>
    %271 = ttir.empty() : tensor<1x24x7x1024xbf16>
    %272 = "ttir.broadcast"(%270, %271) <{broadcast_dimensions = array<i64: 1, 24, 1, 1>}> : (tensor<1x1x7x1024xbf16>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %273 = ttir.empty() : tensor<1x24x7x1024xbf16>
    %274 = "ttir.add"(%234, %272, %273) : (tensor<1x24x7x1024xbf16>, tensor<1x24x7x1024xbf16>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %275 = ttir.empty() : tensor<1x24x7x1024xf32>
    %276 = "ttir.typecast"(%274, %275) <{conservative_folding = false}> : (tensor<1x24x7x1024xbf16>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %277 = ttir.empty() : tensor<1x24x7xf32>
    %278 = "ttir.max"(%276, %277) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x24x7x1024xf32>, tensor<1x24x7xf32>) -> tensor<1x24x7xf32>
    %279 = ttir.empty() : tensor<1x24x7x1xf32>
    %280 = "ttir.reshape"(%278, %279) <{shape = [1 : i32, 24 : i32, 7 : i32, 1 : i32]}> : (tensor<1x24x7xf32>, tensor<1x24x7x1xf32>) -> tensor<1x24x7x1xf32>
    %281 = ttir.empty() : tensor<1x24x7x1024xf32>
    %282 = "ttir.broadcast"(%280, %281) <{broadcast_dimensions = array<i64: 1, 1, 1, 1024>}> : (tensor<1x24x7x1xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %283 = ttir.empty() : tensor<1x24x7x1024xf32>
    %284 = "ttir.subtract"(%276, %282, %283) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %285 = ttir.empty() : tensor<1x24x7x1024xf32>
    %286 = "ttir.exp"(%284, %285) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %287 = ttir.empty() : tensor<1x24x7xf32>
    %288 = "ttir.sum"(%286, %287) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x24x7x1024xf32>, tensor<1x24x7xf32>) -> tensor<1x24x7xf32>
    %289 = ttir.empty() : tensor<1x24x7x1xf32>
    %290 = "ttir.reshape"(%288, %289) <{shape = [1 : i32, 24 : i32, 7 : i32, 1 : i32]}> : (tensor<1x24x7xf32>, tensor<1x24x7x1xf32>) -> tensor<1x24x7x1xf32>
    %291 = ttir.empty() : tensor<1x24x7x1024xf32>
    %292 = "ttir.broadcast"(%290, %291) <{broadcast_dimensions = array<i64: 1, 1, 1, 1024>}> : (tensor<1x24x7x1xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %293 = ttir.empty() : tensor<1x24x7x1024xf32>
    %294 = "ttir.div"(%286, %292, %293) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %295 = ttir.empty() : tensor<1x24x7x1024xbf16>
    %296 = "ttir.typecast"(%294, %295) <{conservative_folding = false}> : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %297 = ttir.empty() : tensor<24x7x1024xbf16>
    %298 = "ttir.reshape"(%296, %297) <{shape = [24 : i32, 7 : i32, 1024 : i32]}> : (tensor<1x24x7x1024xbf16>, tensor<24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %299 = ttir.empty() : tensor<1x1024x3072xbf16>
    %300 = "ttir.reshape"(%arg5, %299) <{shape = [1 : i32, 1024 : i32, 3072 : i32]}> : (tensor<1024x3072xbf16>, tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %301 = ttir.empty() : tensor<1024x3072xbf16>
    %302 = "ttir.reshape"(%300, %301) <{shape = [1024 : i32, 3072 : i32]}> : (tensor<1x1024x3072xbf16>, tensor<1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %303 = ttir.empty() : tensor<3072x1024xbf16>
    %304 = "ttir.permute"(%302, %303) <{permutation = array<i64: 1, 0>}> : (tensor<1024x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<3072x1024xbf16>
    %305 = "ttir.dot_general"(%78, %304) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %306 = ttir.empty() : tensor<1x7x8x128xbf16>
    %307 = "ttir.reshape"(%305, %306) <{shape = [1 : i32, 7 : i32, 8 : i32, 128 : i32]}> : (tensor<7x1024xbf16>, tensor<1x7x8x128xbf16>) -> tensor<1x7x8x128xbf16>
    %308 = ttir.empty() : tensor<1x8x7x128xbf16>
    %309 = "ttir.permute"(%307, %308) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x8x128xbf16>, tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xbf16>
    %310 = ttir.empty() : tensor<1x8x1024x128xbf16>
    %311 = "ttir.scatter"(%arg11, %168, %309, %310) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>, tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %312 = ttir.empty() : tensor<1x8x1x1024x128xbf16>
    %313 = "ttir.reshape"(%311, %312) <{shape = [1 : i32, 8 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x1024x128xbf16>, tensor<1x8x1x1024x128xbf16>) -> tensor<1x8x1x1024x128xbf16>
    %314 = ttir.empty() : tensor<1x8x3x1024x128xbf16>
    %315 = "ttir.broadcast"(%313, %314) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x8x1x1024x128xbf16>, tensor<1x8x3x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %316 = ttir.empty() : tensor<24x1024x128xbf16>
    %317 = "ttir.reshape"(%315, %316) <{shape = [24 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x3x1024x128xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %318 = "ttir.dot_general"(%298, %317) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %319 = ttir.empty() : tensor<1x24x7x128xbf16>
    %320 = "ttir.reshape"(%318, %319) <{shape = [1 : i32, 24 : i32, 7 : i32, 128 : i32]}> : (tensor<24x7x128xbf16>, tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %321 = ttir.empty() : tensor<1x7x24x128xbf16>
    %322 = "ttir.permute"(%320, %321) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x24x7x128xbf16>, tensor<1x7x24x128xbf16>) -> tensor<1x7x24x128xbf16>
    %323 = ttir.empty() : tensor<7x3072xbf16>
    %324 = "ttir.reshape"(%322, %323) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x24x128xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %325 = ttir.empty() : tensor<1x3072x3072xbf16>
    %326 = "ttir.reshape"(%arg4, %325) <{shape = [1 : i32, 3072 : i32, 3072 : i32]}> : (tensor<3072x3072xbf16>, tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %327 = ttir.empty() : tensor<3072x3072xbf16>
    %328 = "ttir.reshape"(%326, %327) <{shape = [3072 : i32, 3072 : i32]}> : (tensor<1x3072x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %329 = ttir.empty() : tensor<3072x3072xbf16>
    %330 = "ttir.permute"(%328, %329) <{permutation = array<i64: 1, 0>}> : (tensor<3072x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %331 = "ttir.dot_general"(%324, %330) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %332 = ttir.empty() : tensor<1x7x3072xbf16>
    %333 = "ttir.reshape"(%331, %332) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %334 = ttir.empty() : tensor<1x7x3072xbf16>
    %335 = "ttir.add"(%32, %333, %334) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %336 = ttir.empty() : tensor<1x1x3072xbf16>
    %337 = "ttir.reshape"(%arg18, %336) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %338 = ttir.empty() : tensor<3072xbf16>
    %339 = "ttir.reshape"(%337, %338) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %340 = ttir.empty() : tensor<3072xf32>
    %341 = "ttir.typecast"(%339, %340) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %342 = ttir.empty() : tensor<1x1x3072xf32>
    %343 = "ttir.reshape"(%341, %342) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %344 = ttir.empty() : tensor<1x7x3072xf32>
    %345 = "ttir.broadcast"(%343, %344) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %346 = ttir.empty() : tensor<1x7x3072xf32>
    %347 = "ttir.typecast"(%335, %346) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %348 = ttir.empty() : tensor<1x7x3072xf32>
    %349 = "ttir.pow"(%347, %4, %348) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %350 = ttir.empty() : tensor<1x7xf32>
    %351 = "ttir.sum"(%349, %350) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %352 = ttir.empty() : tensor<1x7xf32>
    %353 = "ttir.multiply"(%351, %3, %352) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %354 = ttir.empty() : tensor<1x7x1xf32>
    %355 = "ttir.reshape"(%353, %354) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %356 = ttir.empty() : tensor<1x7x1xf32>
    %357 = "ttir.add"(%355, %56, %356) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %358 = ttir.empty() : tensor<1x7x1xf32>
    %359 = "ttir.rsqrt"(%357, %358) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %360 = ttir.empty() : tensor<1x7xf32>
    %361 = "ttir.reshape"(%359, %360) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %362 = ttir.empty() : tensor<1x7x1xf32>
    %363 = "ttir.reshape"(%361, %362) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %364 = ttir.empty() : tensor<1x7x3072xf32>
    %365 = "ttir.broadcast"(%363, %364) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %366 = ttir.empty() : tensor<1x7x3072xf32>
    %367 = "ttir.multiply"(%347, %365, %366) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %368 = ttir.empty() : tensor<1x7x3072xbf16>
    %369 = "ttir.typecast"(%367, %368) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %370 = ttir.empty() : tensor<1x7x3072xf32>
    %371 = "ttir.typecast"(%369, %370) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %372 = ttir.empty() : tensor<1x7x3072xf32>
    %373 = "ttir.multiply"(%345, %371, %372) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %374 = ttir.empty() : tensor<1x7x3072xbf16>
    %375 = "ttir.typecast"(%373, %374) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %376 = ttir.empty() : tensor<7x3072xbf16>
    %377 = "ttir.reshape"(%375, %376) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %378 = ttir.empty() : tensor<1x8192x3072xbf16>
    %379 = "ttir.reshape"(%arg19, %378) <{shape = [1 : i32, 8192 : i32, 3072 : i32]}> : (tensor<8192x3072xbf16>, tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %380 = ttir.empty() : tensor<8192x3072xbf16>
    %381 = "ttir.reshape"(%379, %380) <{shape = [8192 : i32, 3072 : i32]}> : (tensor<1x8192x3072xbf16>, tensor<8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %382 = ttir.empty() : tensor<3072x8192xbf16>
    %383 = "ttir.permute"(%381, %382) <{permutation = array<i64: 1, 0>}> : (tensor<8192x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %384 = "ttir.dot_general"(%377, %383) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %385 = ttir.empty() : tensor<1x7x8192xbf16>
    %386 = "ttir.reshape"(%384, %385) <{shape = [1 : i32, 7 : i32, 8192 : i32]}> : (tensor<7x8192xbf16>, tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %387 = ttir.empty() : tensor<1x7x8192xf32>
    %388 = "ttir.typecast"(%386, %387) <{conservative_folding = false}> : (tensor<1x7x8192xbf16>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %389 = ttir.empty() : tensor<1x7x8192xbf16>
    %390 = "ttir.sigmoid"(%386, %389) : (tensor<1x7x8192xbf16>, tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %391 = ttir.empty() : tensor<1x7x8192xf32>
    %392 = "ttir.typecast"(%390, %391) <{conservative_folding = false}> : (tensor<1x7x8192xbf16>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %393 = ttir.empty() : tensor<1x7x8192xf32>
    %394 = "ttir.multiply"(%388, %392, %393) : (tensor<1x7x8192xf32>, tensor<1x7x8192xf32>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %395 = ttir.empty() : tensor<1x7x8192xbf16>
    %396 = "ttir.typecast"(%394, %395) <{conservative_folding = false}> : (tensor<1x7x8192xf32>, tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %397 = ttir.empty() : tensor<1x7x8192xf32>
    %398 = "ttir.typecast"(%396, %397) <{conservative_folding = false}> : (tensor<1x7x8192xbf16>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %399 = ttir.empty() : tensor<1x8192x3072xbf16>
    %400 = "ttir.reshape"(%arg3, %399) <{shape = [1 : i32, 8192 : i32, 3072 : i32]}> : (tensor<8192x3072xbf16>, tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %401 = ttir.empty() : tensor<8192x3072xbf16>
    %402 = "ttir.reshape"(%400, %401) <{shape = [8192 : i32, 3072 : i32]}> : (tensor<1x8192x3072xbf16>, tensor<8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %403 = ttir.empty() : tensor<3072x8192xbf16>
    %404 = "ttir.permute"(%402, %403) <{permutation = array<i64: 1, 0>}> : (tensor<8192x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %405 = "ttir.dot_general"(%377, %404) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %406 = ttir.empty() : tensor<1x7x8192xbf16>
    %407 = "ttir.reshape"(%405, %406) <{shape = [1 : i32, 7 : i32, 8192 : i32]}> : (tensor<7x8192xbf16>, tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %408 = ttir.empty() : tensor<1x7x8192xf32>
    %409 = "ttir.typecast"(%407, %408) <{conservative_folding = false}> : (tensor<1x7x8192xbf16>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %410 = ttir.empty() : tensor<1x7x8192xf32>
    %411 = "ttir.multiply"(%398, %409, %410) : (tensor<1x7x8192xf32>, tensor<1x7x8192xf32>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
    %412 = ttir.empty() : tensor<1x7x8192xbf16>
    %413 = "ttir.typecast"(%411, %412) <{conservative_folding = false}> : (tensor<1x7x8192xf32>, tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %414 = ttir.empty() : tensor<7x8192xbf16>
    %415 = "ttir.reshape"(%413, %414) <{shape = [7 : i32, 8192 : i32]}> : (tensor<1x7x8192xbf16>, tensor<7x8192xbf16>) -> tensor<7x8192xbf16>
    %416 = ttir.empty() : tensor<1x3072x8192xbf16>
    %417 = "ttir.reshape"(%arg2, %416) <{shape = [1 : i32, 3072 : i32, 8192 : i32]}> : (tensor<3072x8192xbf16>, tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %418 = ttir.empty() : tensor<3072x8192xbf16>
    %419 = "ttir.reshape"(%417, %418) <{shape = [3072 : i32, 8192 : i32]}> : (tensor<1x3072x8192xbf16>, tensor<3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %420 = ttir.empty() : tensor<8192x3072xbf16>
    %421 = "ttir.permute"(%419, %420) <{permutation = array<i64: 1, 0>}> : (tensor<3072x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %422 = "ttir.dot_general"(%415, %421) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %423 = ttir.empty() : tensor<1x7x3072xbf16>
    %424 = "ttir.reshape"(%422, %423) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %425 = ttir.empty() : tensor<1x7x3072xbf16>
    %426 = "ttir.add"(%335, %424, %425) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %427 = ttir.empty() : tensor<1x7x3072xf32>
    %428 = "ttir.typecast"(%426, %427) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %429 = ttir.empty() : tensor<1x7x3072xf32>
    %430 = "ttir.pow"(%428, %4, %429) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %431 = ttir.empty() : tensor<1x7xf32>
    %432 = "ttir.sum"(%430, %431) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %433 = ttir.empty() : tensor<1x7xf32>
    %434 = "ttir.multiply"(%432, %3, %433) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %435 = ttir.empty() : tensor<1x7x1xf32>
    %436 = "ttir.reshape"(%434, %435) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %437 = ttir.empty() : tensor<1x7x1xf32>
    %438 = "ttir.add"(%436, %56, %437) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %439 = ttir.empty() : tensor<1x7x1xf32>
    %440 = "ttir.rsqrt"(%438, %439) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %441 = ttir.empty() : tensor<1x7xf32>
    %442 = "ttir.reshape"(%440, %441) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %443 = ttir.empty() : tensor<1x7x1xf32>
    %444 = "ttir.reshape"(%442, %443) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %445 = ttir.empty() : tensor<1x7x3072xf32>
    %446 = "ttir.broadcast"(%444, %445) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %447 = ttir.empty() : tensor<1x7x3072xf32>
    %448 = "ttir.multiply"(%428, %446, %447) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %449 = ttir.empty() : tensor<1x7x3072xbf16>
    %450 = "ttir.typecast"(%448, %449) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %451 = ttir.empty() : tensor<1x7x3072xf32>
    %452 = "ttir.typecast"(%450, %451) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %453 = ttir.empty() : tensor<1x7x3072xf32>
    %454 = "ttir.multiply"(%18, %452, %453) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %455 = ttir.empty() : tensor<1x7x3072xbf16>
    %456 = "ttir.typecast"(%454, %455) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %457 = ttir.empty() : tensor<7x3072xbf16>
    %458 = "ttir.reshape"(%456, %457) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %459 = ttir.empty() : tensor<1x128256x3072xbf16>
    %460 = "ttir.reshape"(%arg0, %459) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %461 = ttir.empty() : tensor<128256x3072xbf16>
    %462 = "ttir.reshape"(%460, %461) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %463 = ttir.empty() : tensor<3072x128256xbf16>
    %464 = "ttir.permute"(%462, %463) <{permutation = array<i64: 1, 0>}> : (tensor<128256x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<3072x128256xbf16>
    %465 = "ttir.dot_general"(%458, %464) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %466 = ttir.empty() : tensor<1x7x128256xbf16>
    %467 = "ttir.reshape"(%465, %466) <{shape = [1 : i32, 7 : i32, 128256 : i32]}> : (tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %467 : tensor<1x7x128256xbf16>
  }
}
2025-09-08 14:24:53.636 (   7.309s) [        6D2F5000]      module_builder.cc:531   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2025-09-08 14:24:53.636 (   7.309s) [        6D2F5000]      module_builder.cc:545   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2025-09-08 14:24:53.636 (   7.309s) [        6D2F5000]      module_builder.cc:555   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2025-09-08 14:24:53.710 (   7.383s) [        6D2F5000]      module_builder.cc:598      1| TTNN Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x1>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x1, chipIds = [0]>
      func.func @main_const_eval_0(%arg0: tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<<system_memory>>, value = dense<"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tensor<1024xsi32>}> : () -> tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1024xsi32, #ttnn.buffer_type<system_memory>>>>
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1024xsi32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1024xsi32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %3 = "ttnn.to_device"(%2, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %4 = "ttnn.constant"() <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<<system_memory>>, value = dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xsi32>}> : () -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xsi32, #ttnn.buffer_type<system_memory>>>>
        %5 = "ttnn.to_layout"(%4) <{layout = #ttnn.layout<tile>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xsi32, #ttnn.buffer_type<system_memory>>>>) -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xsi32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %6 = "ttnn.to_device"(%5, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %7 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<7x1024>}> : (!ttnn.device) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %8 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 1 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<7x1024>}> : (!ttnn.device) -> tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %9 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1024 : i32]}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1024xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<7x1>}> : (tensor<1x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %11 = "ttnn.reshape"(%6) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.neg"(%11) : (tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %13 = "ttnn.add"(%9, %12) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<7x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %14 = "ttnn.typecast"(%13) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %16 = "ttnn.ge"(%14, %15) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %17 = "ttnn.typecast"(%16) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<7x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %19 = "ttnn.repeat"(%18) <{repeat_dims = #ttnn.shape<7x1024>}> : (tensor<1x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.where"(%17, %19, %7) : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.reshape"(%20) <{shape = [1 : i32, 1 : i32, 7 : i32, 1024 : i32]}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.reshape"(%10) <{shape = [1 : i32, 1 : i32, 7 : i32, 1024 : i32]}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<7x1024xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.typecast"(%23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1024xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x1x7x1024xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %22, %24 : tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main_const_eval_1(%arg0: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.typecast"(%1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main_const_eval_2(%arg0: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.typecast"(%1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main_const_eval_3(%arg0: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.typecast"(%1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main_const_eval_4(%arg0: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.repeat"(%1) <{repeat_dims = #ttnn.shape<7x1>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %5 = "ttnn.reshape"(%2) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %3, %4, %5 : tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main_const_eval_5(%arg0: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %1 = "ttnn.reshape"(%arg0) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.repeat"(%1) <{repeat_dims = #ttnn.shape<1x24x7x1024>}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %3 = "ttnn.reshape"(%2) <{shape = [24 : i32, 7 : i32, 1024 : i32]}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %3 : tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main(%arg0: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_1"}, %arg10: tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_3"}, %arg12: tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0:2 = ttcore.load_cached(@main_const_eval_0, [%arg12]) : (tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %1 = ttcore.load_cached(@main_const_eval_1, [%arg18]) : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %2 = ttcore.load_cached(@main_const_eval_2, [%arg20]) : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg8]) : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %4:3 = ttcore.load_cached(@main_const_eval_4, [%arg1]) : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %5 = ttcore.load_cached(@main_const_eval_5, [%arg13]) : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %6 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x1>}> : () -> !ttnn.device
        %7 = "ttnn.full"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7>}> : (!ttnn.device) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %8 = "ttnn.full"(%6) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7x3072>}> : (!ttnn.device) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %9 = "ttnn.typecast"(%arg6) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.reshape"(%9) <{shape = [7 : i32]}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %11 = "ttnn.from_device"(%10) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.to_layout"(%11) <{layout = #ttnn.layout<row_major>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %13 = "ttnn.to_device"(%12, %6) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %14 = "ttnn.embedding"(%13, %arg7) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.typecast"(%14) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %16 = "ttnn.reshape"(%15) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %17 = "ttnn.pow"(%16, %8) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.sum"(%17) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %19 = "ttnn.multiply"(%18, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.add"(%19, %4#0) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%4#0) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.rsqrt"(%20) : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.reshape"(%21) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.multiply"(%15, %22) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.multiply"(%3, %23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %25 = "ttnn.typecast"(%24) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %26 = "ttnn.matmul"(%25, %arg17) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %27 = "ttnn.reshape"(%26) <{shape = [1 : i32, 7 : i32, 24 : i32, 128 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x24x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %28 = "ttnn.permute"(%27) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x24x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x7x24x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %29 = "ttnn.typecast"(%28) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %30 = "ttnn.reshape"(%29) <{shape = [24 : i32, 7 : i32, 128 : i32]}> : (tensor<1x24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %31 = "ttnn.reshape"(%arg14) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %32 = "ttnn.typecast"(%arg9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %33 = "ttnn.reshape"(%32) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %34 = "ttnn.matmul"(%31, %33) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %35 = "ttnn.permute"(%34) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %36 = "ttnn.reshape"(%35) <{shape = [1 : i32, 1 : i32, 7 : i32, 64 : i32]}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %37 = "ttnn.reshape"(%35) <{shape = [1 : i32, 1 : i32, 7 : i32, 64 : i32]}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %38 = "ttnn.concat"(%36, %37) <{dim = 3 : si32}> : (tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %39 = "ttnn.cos"(%38) : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %40 = "ttnn.reshape"(%39) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %41 = "ttnn.multiply"(%30, %40) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %42 = "ttnn.typecast"(%41) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %43 = "ttnn.slice_static"(%28) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 24 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %44 = "ttnn.neg"(%43) : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %45 = "ttnn.reshape"(%44) <{shape = [24 : i32, 7 : i32, 64 : i32]}> : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %46 = "ttnn.slice_static"(%28) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 24 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %47 = "ttnn.reshape"(%46) <{shape = [24 : i32, 7 : i32, 64 : i32]}> : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %48 = "ttnn.concat"(%45, %47) <{dim = 2 : si32}> : (tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<24x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %49 = "ttnn.typecast"(%48) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %50 = "ttnn.sin"(%38) : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %51 = "ttnn.reshape"(%50) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %52 = "ttnn.multiply"(%49, %51) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %53 = "ttnn.typecast"(%52) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<24x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %54 = "ttnn.add"(%42, %53) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %55 = "ttnn.matmul"(%25, %arg15) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %56 = "ttnn.reshape"(%55) <{shape = [1 : i32, 7 : i32, 8 : i32, 128 : i32]}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %57 = "ttnn.permute"(%56) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %58 = "ttnn.typecast"(%57) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %59 = "ttnn.multiply"(%58, %39) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %60 = "ttnn.typecast"(%59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %61 = "ttnn.slice_static"(%57) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 8 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %62 = "ttnn.neg"(%61) : (tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %63 = "ttnn.slice_static"(%57) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 8 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %64 = "ttnn.concat"(%62, %63) <{dim = 3 : si32}> : (tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x8x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %65 = "ttnn.typecast"(%64) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %66 = "ttnn.multiply"(%65, %50) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %67 = "ttnn.typecast"(%66) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x8x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %68 = "ttnn.add"(%60, %67) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%arg16, %68) <{batch_offset = 0 : i32}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %69 = "ttnn.reshape"(%arg16) <{shape = [1 : i32, 8 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %70 = "ttnn.repeat"(%69) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %71 = "ttnn.reshape"(%70) <{shape = [1 : i32, 24 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 24576 + d1 * 1024 + d2, d3), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %72 = "ttnn.permute"(%71) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 24576 + d1 * 1024 + d2, d3), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 3072 + d1 * 128 + d2, d3), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 24576 + d1 * 1024 + d2, d3), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %73 = "ttnn.reshape"(%72) <{shape = [24 : i32, 128 : i32, 1024 : i32]}> : (tensor<1x24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 3072 + d1 * 128 + d2, d3), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 3072 + d1 * 128 + d2, d3), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %74 = "ttnn.matmul"(%54, %73) <{transpose_a = false, transpose_b = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<24x128x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %75 = "ttnn.typecast"(%74) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %76 = "ttnn.multiply"(%75, %5) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %77 = "ttnn.typecast"(%76) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %78 = "ttnn.reshape"(%77) <{shape = [1 : i32, 24 : i32, 7 : i32, 1024 : i32]}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %79 = "ttnn.reshape"(%arg9) <{shape = [1 : i32, 1 : i32, 7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %80 = "ttnn.typecast"(%79) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %81 = "ttnn.gt"(%0#1, %80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0#1) <{force = false}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %82 = "ttnn.typecast"(%81) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %83 = "ttnn.typecast"(%82) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %84 = "ttnn.multiply"(%0#0, %83) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0#0) <{force = false}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %85 = "ttnn.typecast"(%84) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x1x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %86 = "ttnn.add"(%78, %85) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x1x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %87 = "ttnn.typecast"(%86) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %88 = "ttnn.softmax"(%87) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %89 = "ttnn.typecast"(%88) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x24x7x1024xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %90 = "ttnn.reshape"(%89) <{shape = [24 : i32, 7 : i32, 1024 : i32]}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %91 = "ttnn.matmul"(%25, %arg5) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %92 = "ttnn.reshape"(%91) <{shape = [1 : i32, 7 : i32, 8 : i32, 128 : i32]}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<7x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %93 = "ttnn.permute"(%92) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x7x8x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%arg11, %93) <{batch_offset = 0 : i32}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x8x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %94 = "ttnn.reshape"(%arg11) <{shape = [1 : i32, 8 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1x8x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %95 = "ttnn.repeat"(%94) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x8x1x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 8192 + d1 * 1024 + d2 * 1024 + d3, d4), <1x1>, memref<256x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %96 = "ttnn.reshape"(%95) <{shape = [24 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x8x3x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 24576 + d1 * 3072 + d2 * 1024 + d3, d4), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %97 = "ttnn.matmul"(%90, %96) <{transpose_a = false, transpose_b = false}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<24x1024x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<768x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<24x7x1024xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x32x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %98 = "ttnn.reshape"(%97) <{shape = [1 : i32, 24 : i32, 7 : i32, 128 : i32]}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %99 = "ttnn.concatenate_heads"(%98) : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x24x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 768 + d1 * 32 + d2, d3), <1x1>, memref<24x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %100 = "ttnn.reshape"(%99) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %101 = "ttnn.matmul"(%100, %arg4) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %102 = "ttnn.add"(%14, %101) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %103 = "ttnn.typecast"(%102) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %104 = "ttnn.reshape"(%103) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %105 = "ttnn.pow"(%104, %8) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %106 = "ttnn.sum"(%105) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %107 = "ttnn.multiply"(%106, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %108 = "ttnn.add"(%107, %4#1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%4#1) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %109 = "ttnn.rsqrt"(%108) : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %110 = "ttnn.reshape"(%109) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %111 = "ttnn.multiply"(%103, %110) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %112 = "ttnn.multiply"(%1, %111) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %113 = "ttnn.typecast"(%112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %114 = "ttnn.matmul"(%113, %arg19) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %115 = "ttnn.typecast"(%114) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %116 = "ttnn.sigmoid"(%114) : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %117 = "ttnn.typecast"(%116) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %118 = "ttnn.multiply"(%115, %117) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %119 = "ttnn.matmul"(%113, %arg3) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %120 = "ttnn.typecast"(%119) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %121 = "ttnn.multiply"(%118, %120) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %122 = "ttnn.typecast"(%121) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<7x8192xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %123 = "ttnn.matmul"(%122, %arg2) <{transpose_a = false, transpose_b = true}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<7x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %124 = "ttnn.add"(%102, %123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %125 = "ttnn.typecast"(%124) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %126 = "ttnn.reshape"(%125) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %127 = "ttnn.pow"(%126, %8) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %128 = "ttnn.sum"(%127) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %129 = "ttnn.multiply"(%128, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %130 = "ttnn.add"(%129, %4#2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%4#2) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %131 = "ttnn.rsqrt"(%130) : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %132 = "ttnn.reshape"(%131) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %133 = "ttnn.multiply"(%125, %132) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %134 = "ttnn.multiply"(%2, %133) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %135 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %136 = "ttnn.matmul"(%135, %arg0) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %137 = "ttnn.reshape"(%136) <{shape = [1 : i32, 7 : i32, 128256 : i32]}> : (tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %137 : tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
    }
  }
}
2025-09-08 14:24:53.743 (   7.416s) [        6D2F5000]loaded_executable_insta:441      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2025-09-08 14:24:53.743 (   7.416s) [        6D2F5000]loaded_executable_insta:460      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000]              stubs.inc:76    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-08 14:24:53.743 (   7.417s) [        6D2F5000] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-08 14:24:53.756 (   7.429s) [        6D2F5000] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-08 14:24:53.756 (   7.429s) [        6D2F5000] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]     buffer_instance.cc:532      1| BufferInstance::PJRT_Buffer_Device
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640] executable_instance.cc:138      1| ExecutableInstance::PJRT_Executable_NumOutputs
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]loaded_executable_insta:497      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2025-09-08 14:24:53.766 (   7.439s) [        3F7FE640]loaded_executable_insta:81       1| LoadedExecutableInstance::Execute
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]     buffer_instance.cc:437      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:25:44.039 (  57.712s) [        3F7FE640]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:25:44.039 (  57.712s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:25:44.039 (  57.712s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:25:44.039 (  57.712s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:25:44.039 (  57.712s) [        6D2F5000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-08 14:25:44.039 (  57.712s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:25:44.039 (  57.713s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:25:44.039 (  57.713s) [        EA7FC640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:25:44.042 (  57.715s) [        6D2F5000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-08 14:25:44.042 (  57.715s) [        6D2F5000]     buffer_instance.cc:425      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-08 14:25:44.042 (  57.715s) [        6D2F5000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-08 14:25:44.042 (  57.715s) [        6D2F5000]     buffer_instance.cc:447      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-08 14:25:44.042 (  57.715s) [        6D2F5000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-08 14:25:44.045 (  57.718s) [        12FFD640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-08 14:25:44.067 (  57.740s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:44.067 (  57.740s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:44.067 (  57.741s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:44.067 (  57.741s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:44.067 (  57.741s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
args (tensor([[128000,     40,   1093,   4737,  23291,    304,    279]],
       device='xla:0'), tensor([0, 1, 2, 3, 4, 5, 6], device='xla:0'), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='xla:0',
       dtype=torch.bfloat16), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='xla:0',
       dtype=torch.bfloat16))
CausalLMOutputWithPast(loss=None, logits=tensor([[[-0.8398, -2.3438, -0.5352,  ...,  0.8320,  0.8320,  0.8320],
         [-0.1270,  0.2354,  0.8242,  ..., -0.8945, -0.8945, -0.8945],
         [ 1.8359, -1.4219, -0.8828,  ..., -1.4844, -1.4844, -1.4844],
         ...,
         [ 0.0388, -0.8945, -1.4297,  ..., -0.6250, -0.6172, -0.6172],
         [ 0.0250, -1.0312, -1.1016,  ..., -2.3906, -2.3906, -2.3906],
         [-1.1016,  0.0078, -0.7422,  ..., -1.4688, -1.4688, -1.4688]]],
       device='xla:0', dtype=torch.bfloat16), past_key_values=<transformers.cache_utils.StaticCache object at 0x7fc227232350>, hidden_states=None, attentions=None)
Generated token:  the
2025-09-08 14:25:44.638 (  58.311s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:25:44.638 (  58.311s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:25:44.638 (  58.311s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:25:44.638 (  58.311s) [        6D2F5000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-08 14:25:45.051 (  58.724s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.051 (  58.724s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.051 (  58.724s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.051 (  58.725s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.051 (  58.725s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.053 (  58.727s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.055 (  58.729s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.057 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.057 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.058 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.058 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.058 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.058 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.058 (  58.731s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.060 (  58.733s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.062 (  58.735s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.737s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.737s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.737s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.737s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.738s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.064 (  58.738s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.065 (  58.738s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.067 (  58.740s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.069 (  58.742s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.071 (  58.744s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.071 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.071 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.072 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.072 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.072 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.072 (  58.745s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.074 (  58.748s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.076 (  58.750s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.078 (  58.752s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.078 (  58.752s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.079 (  58.752s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.079 (  58.752s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.079 (  58.753s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.079 (  58.753s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.080 (  58.753s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.082 (  58.755s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.084 (  58.757s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.759s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.759s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.759s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.760s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.760s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.086 (  58.760s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.087 (  58.760s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.089 (  58.762s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.091 (  58.764s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.093 (  58.766s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.093 (  58.766s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.093 (  58.767s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.093 (  58.767s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.094 (  58.767s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.094 (  58.767s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.094 (  58.767s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.095 (  58.769s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.097 (  58.771s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.099 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.099 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.099 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.100 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.100 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.100 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.100 (  58.773s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.102 (  58.775s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.104 (  58.778s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.780s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.780s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.780s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.780s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.780s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.781s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.107 (  58.781s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.110 (  58.783s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.112 (  58.785s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.788s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.788s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.788s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.788s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.789s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.115 (  58.789s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.116 (  58.789s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.118 (  58.792s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.121 (  58.795s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.124 (  58.797s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.124 (  58.797s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.124 (  58.797s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.124 (  58.798s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.124 (  58.798s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.125 (  58.798s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.125 (  58.798s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.127 (  58.801s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.130 (  58.803s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.132 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.133 (  58.806s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.136 (  58.810s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.139 (  58.812s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.141 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.815s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.142 (  58.816s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.145 (  58.818s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.147 (  58.820s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.149 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.150 (  58.823s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.153 (  58.826s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.156 (  58.829s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.158 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.158 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.159 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.159 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.159 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.159 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.159 (  58.832s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.161 (  58.835s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.164 (  58.837s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.840s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.840s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.840s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.840s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.841s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.167 (  58.841s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.168 (  58.841s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.170 (  58.843s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.173 (  58.846s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.175 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.849s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.176 (  58.850s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.179 (  58.852s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.181 (  58.854s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.183 (  58.856s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.183 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.183 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.183 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.184 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.184 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.184 (  58.857s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.186 (  58.859s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.188 (  58.861s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.863s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.863s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.863s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.864s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.864s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.190 (  58.864s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.191 (  58.864s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.193 (  58.866s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.195 (  58.868s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.197 (  58.871s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.197 (  58.871s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.198 (  58.871s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.198 (  58.871s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.198 (  58.871s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.198 (  58.872s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.198 (  58.872s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.200 (  58.874s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.202 (  58.875s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.204 (  58.877s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.204 (  58.877s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.204 (  58.877s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.204 (  58.878s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.204 (  58.878s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.205 (  58.878s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.205 (  58.878s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.207 (  58.880s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.209 (  58.882s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.884s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.884s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.884s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.884s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.884s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.885s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.211 (  58.885s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.213 (  58.886s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.215 (  58.888s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.217 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.217 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.218 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.218 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.218 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.218 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.218 (  58.891s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.220 (  58.893s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.222 (  58.895s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.897s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.897s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.897s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.898s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.898s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.224 (  58.898s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.225 (  58.898s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.227 (  58.900s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.228 (  58.902s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.230 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.231 (  58.904s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.233 (  58.907s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.236 (  58.909s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.911s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.911s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.911s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.911s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.912s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.238 (  58.912s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.239 (  58.912s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.240 (  58.913s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.242 (  58.916s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.244 (  58.917s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.244 (  58.917s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.244 (  58.917s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.244 (  58.918s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.245 (  58.918s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.245 (  58.918s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.245 (  58.918s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.247 (  58.920s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.249 (  58.922s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.251 (  58.924s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.251 (  58.924s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.251 (  58.925s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.283 (  58.956s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.283 (  58.956s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.283 (  58.956s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.283 (  58.957s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.284 (  58.957s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.286 (  58.959s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.287 (  58.961s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.289 (  58.963s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.290 (  58.963s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.290 (  58.963s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.290 (  58.963s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:45.290 (  58.963s) [        6D2F5000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-08 14:25:46.775 (  60.448s) [        6D2F5000]     client_instance.cc:312      1| ClientInstance::PJRT_Client_Destroy
2025-09-08 14:25:46.775 (  60.448s) [        6D2F5000]     client_instance.cc:53       1| ClientInstance::~ClientInstance
